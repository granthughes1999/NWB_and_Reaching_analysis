{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is to take the .xlsx file created by reach_Curator_py38_v3.py script, and adds in the missing rows for T6000, T5000 values\n",
    "- has multiple steps\n",
    "1. Backs up the raw .xlsx file created by Reach_Curator_py38_v3.py\n",
    "2. Takes raw .xlsx file created by Reach_Curator_py38_v3.py --> Adds in missing rows by reading _events.txt file and comparing it --> puts this modifed version with added rows in the root folder Grant_curate\n",
    "3. Once you have manually curated the session (ie. added reaches) using the Reach_Curator_py38_v3.py\n",
    "4. this will back up that manually curated .xlsx file into this folder, which it creates if it does not exist already --> completed_manual_curation_backup\n",
    "5. finally, it will remove any rows that have no values for ReachInit > ReachMax > ReachEnd_ --> it will then put this final cleaned version back into the root folder that the Reach_Curator_py38_v3.py saves and reads from --> Grant_curate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify these three variables as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'G:\\Grant\\behavior_data\\DLC_net' # change this to your root path where all the analysis folder live, i currently use is G:\\Grant\\behavior_data\\DLC_net\n",
    "root_folder = 'grant_reach10_swingDoor-christie-2025-04-21' # change this to your root folder for one specfic mouse (this should contain multiple sessions)\n",
    "\n",
    "# Set the specific mouse session to analyze\n",
    "session_info = '20250426_session001'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new session_option for each session\n",
    "- class that lets you load data for specific mouse sesssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_path: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\n"
     ]
    }
   ],
   "source": [
    "main_path = rf'{root_path}\\{root_folder}'\n",
    "print(f'main_path: {main_path}')\n",
    "\n",
    "class select_mouse_session:\n",
    "    def __init__(self, mouse, session_date, session_ID):\n",
    "        self.mouse = mouse\n",
    "        self.session_date = session_date\n",
    "        self.session_ID = session_ID\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Mouse: {self.mouse}, Session Date: {self.session_date}, Session ID: {self.session_ID}\"\n",
    "    \n",
    "    def get_mouse_session_files(self):\n",
    "        mouse_session = f\"{self.mouse}_{self.session_date}_{self.session_ID}\"\n",
    "        xlsx_file = rf'{main_path}\\Grant_curate\\{self.session_date}_christielab_{self.session_ID}.xlsx'\n",
    "        txt_file = rf\"G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\videos\\{self.session_date}\\christielab\\{self.session_ID}\\{self.session_date}_christielab_{self.session_ID}_events_shifted.txt\"\n",
    "        xlsx_orig = rf'G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\curator_direct_backup\\{self.session_date}_christielab_{self.session_ID}.xlsx'\n",
    "        \n",
    "        return xlsx_file, txt_file, xlsx_orig\n",
    "    \n",
    "    def get_mouse_info(self):\n",
    "        mouse_info = {\n",
    "            'mouse': self.mouse,\n",
    "            'session_date': self.session_date,\n",
    "            'session_ID': self.session_ID\n",
    "        }\n",
    "        return mouse_info\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️YOU ARE ABOUT TO MODIFY --> 20250426_session001⚠️\n",
      "\n",
      "mouse_info: {'mouse': 'reach10', 'session_date': '20250426', 'session_ID': 'session001'}\n",
      "xlsx_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\20250426_christielab_session001.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(f\"⚠️YOU ARE ABOUT TO MODIFY --> {session_info}⚠️\")\n",
    "print('')\n",
    "\n",
    "if session_info == '20250421_session001':\n",
    "    # create a new class instance\n",
    "    class_intsance = select_mouse_session(mouse='reach10', session_date='20250421', session_ID='session001')\n",
    "    xlsx_file, txt_file, xlsx_orig = class_intsance.get_mouse_session_files()\n",
    "    mouse_info = class_intsance.get_mouse_info()\n",
    "    print(f'mouse_info: {mouse_info}')\n",
    "    print(f'xlsx_file: {xlsx_file}')\n",
    "\n",
    "if session_info == '20250424_session001':\n",
    "    # create a new class instance\n",
    "    class_intsance = select_mouse_session(mouse='reach10', session_date='20250424', session_ID='session001')\n",
    "    xlsx_file, txt_file, xlsx_orig = class_intsance.get_mouse_session_files()\n",
    "    mouse_info = class_intsance.get_mouse_info()\n",
    "    print(f'mouse_info: {mouse_info}')\n",
    "    print(f'xlsx_file: {xlsx_file}')\n",
    "    \n",
    "if session_info == '20250426_session001':\n",
    "    # create a new class instance\n",
    "    class_intsance = select_mouse_session(mouse='reach10', session_date='20250426', session_ID='session001')\n",
    "    xlsx_file, txt_file, xlsx_orig = class_intsance.get_mouse_session_files()\n",
    "    mouse_info = class_intsance.get_mouse_info()\n",
    "    print(f'mouse_info: {mouse_info}')\n",
    "    print(f'xlsx_file: {xlsx_file}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "session_save_name: reach10_20250426_session001\n",
      "\n",
      "mouse: reach10\n",
      "session_date: 20250426\n",
      "session_ID: session001\n",
      "original_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\n",
      "backup_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\reach10_20250426_session001\\reach_curator_direct_backup\n"
     ]
    }
   ],
   "source": [
    "session_date = mouse_info['session_date']\n",
    "session_ID = mouse_info['session_ID']\n",
    "mouse = mouse_info['mouse']\n",
    "session_save_name = f\"{mouse}_{session_date}_{session_ID}\"\n",
    "print('=========================')\n",
    "print(f'session_save_name: {session_save_name}')\n",
    "print('')\n",
    "print(f'mouse: {mouse}')\n",
    "print(f'session_date: {session_date}')\n",
    "print(f'session_ID: {session_ID}')\n",
    "\n",
    "\n",
    "    # ---- Step 1: Make a backup in curator_backup folder\n",
    "original_dir = os.path.dirname(xlsx_file)\n",
    "backup_dir = os.path.join(original_dir, 'xlsx_backups',session_save_name,'reach_curator_direct_backup')\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "print(f'original_dir: {original_dir}')\n",
    "print(f'backup_dir: {backup_dir}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify existence of session files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Backup saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\reach10_20250426_session001\\reach_curator_direct_backup\\20250426_christielab_session001.xlsx\n",
      "backup_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\reach10_20250426_session001\\reach_curator_direct_backup\\20250426_christielab_session001.xlsx\n",
      "=========================\n",
      "xlsx_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\20250426_christielab_session001.xlsx\n",
      "=========================\n",
      "txt_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\videos\\20250426\\christielab\\session001\\20250426_christielab_session001_events_shifted.txt\n",
      "=========================\n",
      "xlsx_orig: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\curator_direct_backup\\20250426_christielab_session001.xlsx\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(txt_file):\n",
    "    print(f\"⚠️Warning: {txt_file} does not exist⚠️\")\n",
    "\n",
    "backup_file_path = os.path.join(backup_dir, os.path.basename(xlsx_file))\n",
    "if os.path.exists(backup_file_path):\n",
    "    print(f\"⚠️Warning: Backup file already exists at {backup_file_path}⚠️\")\n",
    "else:\n",
    "        # Check if files exist\n",
    "    if not os.path.exists(xlsx_file):\n",
    "        print(f\"⚠️Warning: {xlsx_file} does not exist⚠️\")\n",
    "    else:\n",
    "        # Copy the original file to the backup directory\n",
    "        shutil.copy2(xlsx_file, backup_file_path)\n",
    "        print(f\"✅ Backup saved to: {backup_file_path}\")\n",
    "\n",
    "# ---- (your parsing & merging code goes here)\n",
    "# ... your code to build `combined` DataFrame ...\n",
    "\n",
    "print(f'backup_dir: {backup_file_path}')\n",
    "print('=========================')\n",
    "print(f'xlsx_file: {xlsx_file}')\n",
    "print('=========================')\n",
    "print(f'txt_file: {txt_file}')\n",
    "print('=========================')\n",
    "print(f'xlsx_orig: {xlsx_orig}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the cell that takes the .xlsx file and the .txt file and creates a new .xlsx file with the manual additions\n",
    "- makes a new folder called manual_additions if it does not exist\n",
    "- reads the .xlsx file into a pandas dataframe\n",
    "- reads the .txt file into a pandas dataframe\n",
    "- creates a new dataframe with the manual additions\n",
    "- saves the new dataframe to a new .xlsx file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing xlsx file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\20250426_christielab_session001.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>ReachType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1816</td>\n",
       "      <td>2100</td>\n",
       "      <td>2185</td>\n",
       "      <td>2202</td>\n",
       "      <td>2205</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>2098</td>\n",
       "      <td>1869</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229</td>\n",
       "      <td>4661</td>\n",
       "      <td>4664</td>\n",
       "      <td>4689</td>\n",
       "      <td>4701</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>4659</td>\n",
       "      <td>4283</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6725</td>\n",
       "      <td>6858</td>\n",
       "      <td>6873</td>\n",
       "      <td>6889</td>\n",
       "      <td>6918</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>6856</td>\n",
       "      <td>6779</td>\n",
       "      <td>on_pellet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8911</td>\n",
       "      <td>9414</td>\n",
       "      <td>9428</td>\n",
       "      <td>9448</td>\n",
       "      <td>9459</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>9412</td>\n",
       "      <td>8999</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12129</td>\n",
       "      <td>12336</td>\n",
       "      <td>12353</td>\n",
       "      <td>12374</td>\n",
       "      <td>12385</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>12333</td>\n",
       "      <td>12182</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T6000  T5000  reachInit  reachMax  reachEnd  stim       behaviors  \\\n",
       "0   1816   2100       2185      2202      2205     0          missed   \n",
       "1   4229   4661       4664      4689      4701     0         dropped   \n",
       "2   6725   6858       6873      6889      6918     0  consumed_first   \n",
       "3   8911   9414       9428      9448      9459     0          missed   \n",
       "4  12129  12336      12353     12374     12385     0          missed   \n",
       "\n",
       "   pellet_delivery  pellet_detected  ReachType  \n",
       "0             2098             1869      short  \n",
       "1             4659             4283      short  \n",
       "2             6856             6779  on_pellet  \n",
       "3             9412             8999      short  \n",
       "4            12333            12182      short  "
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing curated xlsx\n",
    "print(f\"Loading existing xlsx file: {xlsx_file}\")\n",
    "df_orig = pd.read_excel(xlsx_file)\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class modify_curator_xlsx_file(object):\n",
    "    def __init__(self, xlsx_file, txt_file,save_df=True):\n",
    "        self.txt_file = txt_file\n",
    "        self.xlsx_file = xlsx_file\n",
    "        self.save_df = save_df\n",
    "\n",
    "        \n",
    "    def create_new_xlxs_file(self):\n",
    "        save_df = self.save_df\n",
    "        # Load the existing xlsx file\n",
    "        df_orig = pd.read_excel(self.xlsx_file)\n",
    "        # Check if the file is empty\n",
    "        txt_file = self.txt_file\n",
    "        if not os.path.exists(txt_file):\n",
    "            print(f\"⚠️Warning: {txt_file} does not exist⚠️\")\n",
    "            return None\n",
    "        # Check if the xlsx file is empty\n",
    "        xlsx_file = self.xlsx_file\n",
    "        if not os.path.exists(xlsx_file):\n",
    "            print(f\"⚠️Warning: {xlsx_file} does not exist⚠️\")\n",
    "            return None\n",
    "\n",
    "        if df_orig.empty:\n",
    "            print(\"⚠️Warning: The xlsx file is empty⚠️\")\n",
    "            return None\n",
    "        \n",
    "        # Normalize column names just in case\n",
    "        df_orig.columns = df_orig.columns.str.strip()\n",
    "\n",
    "        # Load and parse txt as done earlier\n",
    "        events = []\n",
    "        current_event = {}\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    key, value = line.strip().split('\\t')\n",
    "                    value = int(value)\n",
    "                    if key == 'T6000_played':\n",
    "                        if current_event:\n",
    "                            events.append(current_event)\n",
    "                        current_event = {'T6000': value}\n",
    "                    elif key == 'pellet_detected':\n",
    "                        current_event['pellet_detected'] = value\n",
    "                    elif key == 'pellet_delivery':\n",
    "                        current_event['pellet_delivery'] = value\n",
    "                    elif key == 'T5000_played':\n",
    "                        current_event['T5000'] = value\n",
    "        if current_event:\n",
    "            events.append(current_event)\n",
    "\n",
    "        events_df = pd.DataFrame(events)\n",
    "\n",
    "        # Find which T6000s are missing from original file\n",
    "        existing_T6000s = df_orig['T6000'].values\n",
    "        new_rows = events_df[~events_df['T6000'].isin(existing_T6000s)].copy()\n",
    "\n",
    "        # Fill in missing columns to match structure\n",
    "        new_rows['reachInit'] = np.nan\n",
    "        new_rows['reachMax'] = np.nan\n",
    "        new_rows['reachEnd'] = np.nan\n",
    "        new_rows['stim'] = 0\n",
    "        new_rows['behaviors'] = np.nan\n",
    "\n",
    "        # # Reorder columns to match original file\n",
    "        # new_rows = new_rows[['reachinit', 'reachmax', 'reachend', 'stim',\n",
    "        #                      'pellet_delivery', 'pellet_detected', 't6000', 't5000', 'behaviors']]\n",
    "\n",
    "        # Reorder columns to match original file\n",
    "        new_rows = new_rows[['T6000', 'T5000', 'reachInit', 'reachMax',\n",
    "                            'reachEnd', 'stim','behaviors' ,'pellet_delivery', 'pellet_detected']]\n",
    "\n",
    "        # Combine and sort by T6000\n",
    "        combined = pd.concat([df_orig, new_rows], ignore_index=True)\n",
    "        combined = combined.sort_values(by='T6000').reset_index(drop=True)\n",
    "\n",
    "        # Force final column order\n",
    "        combined = combined[['T6000', 'T5000', 'reachInit', 'reachMax',\n",
    "                            'reachEnd', 'stim', 'behaviors',\n",
    "                            'pellet_delivery', 'pellet_detected']]\n",
    "\n",
    "\n",
    "        # ---- Step 2: Save output as the same original file (overwrite it)\n",
    "        xlsx_save_path = xlsx_file\n",
    "        self.xlsx_file = xlsx_save_path\n",
    "\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_dir = os.path.join(original_dir,'xlsx_backups' ,'reach_curator_direct_backup')\n",
    "        backup_file_path = os.path.join(backup_dir, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        backup_added_rows = os.path.join(original_dir, 'xlsx_backups' ,session_save_name,'added_missing_rows_backup')\n",
    "        os.makedirs(backup_added_rows, exist_ok=True)\n",
    "        backup_added_rows_file_path = os.path.join(backup_added_rows, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        # Save the combined DataFrame to the same xlsx file\n",
    "        if save_df:\n",
    "            if os.path.exists(backup_file_path):\n",
    "                combined.to_excel(xlsx_save_path, index=False)\n",
    "                combined.to_excel(backup_added_rows_file_path, index=False)\n",
    "                print(f\"✅ Final merged Excel saved to: {xlsx_save_path}\")\n",
    "                print(f\"✅ Backup saved to: {backup_added_rows_file_path}\")\n",
    "                return combined, xlsx_save_path\n",
    "            else:\n",
    "                print(f\"⚠️Warning: Backup file doesnt exists⚠️\")\n",
    "                print('❌ Stopping the script to avoid overwriting the xlsx file without a back up❌')\n",
    "                print(f\"⚠️Warning: {backup_file_path} does not exist⚠️\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(f\"⚠️Warning: DataFrame not saved to {xlsx_save_path}⚠️\")\n",
    "            print('set save_df to True to save the DataFrame')\n",
    "            return combined\n",
    "    \n",
    "\n",
    "    def drop_empty_reach_rows(self):\n",
    "      \n",
    "        df = pd.read_excel(self.xlsx_file)\n",
    "        # back up the newly created xlsx file\n",
    "        backup_dir_02 = os.path.join(os.path.dirname(self.xlsx_file),'xlsx_backups', session_save_name,'completed_manual_curation_backup')\n",
    "        os.makedirs(backup_dir_02, exist_ok=True)\n",
    "        backup_file_path_02 = os.path.join(backup_dir_02, os.path.basename(self.xlsx_file))\n",
    "        if os.path.exists(backup_file_path_02):\n",
    "            print(f\"⚠️Warning: Backup file already exists at {backup_file_path_02}⚠️\")\n",
    "            print('❌ Stopping the script to avoid overwriting the backup file ❌')\n",
    "            return None \n",
    "        else:\n",
    "            # Copy the original file to the backup directory\n",
    "            shutil.copy2(self.xlsx_file, backup_file_path_02)\n",
    "            print(f\"✅ Backup saved to: {backup_file_path_02}\")\n",
    "        \"\"\"\n",
    "        Drop specified rows from the DataFrame.\n",
    "        \"\"\"\n",
    "        # Drop bad rows\n",
    "        df = df.dropna(subset=['reachInit']).reset_index(drop=True)\n",
    "         # save the DataFrame to the same xlsx file\n",
    "        if self.save_df:\n",
    "            df.to_excel(self.xlsx_file, index=False)\n",
    "            print(f\"✅ Final merged Excel saved to: {self.xlsx_file}\")   \n",
    "              \n",
    "        return df\n",
    "    \n",
    "    def load_orig_xlsx_file(self):\n",
    "        \"\"\"\n",
    "        Load the original xlsx file.\n",
    "        \"\"\"\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_dir = os.path.join(original_dir, 'xlsx_backups',session_save_name ,'reach_curator_direct_backup')\n",
    "        backup_file_path = os.path.join(backup_dir, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        df_orig = pd.read_excel(backup_file_path)\n",
    "        return df_orig, backup_file_path\n",
    "    \n",
    "    def load_added_rows_xlsx(self):\n",
    "        \"\"\"\n",
    "        Load the added rows xlsx file.\n",
    "        \"\"\"\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_added_rows = os.path.join(original_dir,'xlsx_backups' ,session_save_name, 'added_missing_rows_backup')\n",
    "        backup_added_rows_file_path = os.path.join(backup_added_rows, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        df_added_rows = pd.read_excel(backup_added_rows_file_path)\n",
    "        return df_added_rows, backup_added_rows_file_path\n",
    "    \n",
    "    \n",
    "    def load_final_xlsx(self):\n",
    "        \"\"\"\n",
    "        Load the combined xlsx file.\n",
    "        \"\"\"\n",
    "        df_combined = pd.read_excel(self.xlsx_file)\n",
    "        return df_combined, self.xlsx_file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_fail_modify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final merged Excel saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\20250426_christielab_session001.xlsx\n",
      "✅ Backup saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\reach10_20250426_session001\\added_missing_rows_backup\\20250426_christielab_session001.xlsx\n"
     ]
    }
   ],
   "source": [
    "if safe_fail_modify:\n",
    "    mouse_sessions = modify_curator_xlsx_file(xlsx_file, txt_file,save_df=True)\n",
    "    df_modied, xlsx_saved_file = mouse_sessions.create_new_xlxs_file()\n",
    "    df_modied\n",
    "else:\n",
    "    print(f\"⚠️Warning: safe_fail actviated⚠️\")\n",
    "    print('if you want to run the code, please re-run this cell')\n",
    "    print('Note this ')\n",
    "    safe_fail_modify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1816</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229</td>\n",
       "      <td>4661.0</td>\n",
       "      <td>4664.0</td>\n",
       "      <td>4689.0</td>\n",
       "      <td>4701.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>4659.0</td>\n",
       "      <td>4283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6725</td>\n",
       "      <td>6858.0</td>\n",
       "      <td>6873.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>6918.0</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>6856.0</td>\n",
       "      <td>6779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8911</td>\n",
       "      <td>9414.0</td>\n",
       "      <td>9428.0</td>\n",
       "      <td>9448.0</td>\n",
       "      <td>9459.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>9412.0</td>\n",
       "      <td>8999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12129</td>\n",
       "      <td>12336.0</td>\n",
       "      <td>12353.0</td>\n",
       "      <td>12374.0</td>\n",
       "      <td>12385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>12333.0</td>\n",
       "      <td>12182.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T6000    T5000  reachInit  reachMax  reachEnd  stim       behaviors  \\\n",
       "0   1816   2100.0     2185.0    2202.0    2205.0     0          missed   \n",
       "1   4229   4661.0     4664.0    4689.0    4701.0     0         dropped   \n",
       "2   6725   6858.0     6873.0    6889.0    6918.0     0  consumed_first   \n",
       "3   8911   9414.0     9428.0    9448.0    9459.0     0          missed   \n",
       "4  12129  12336.0    12353.0   12374.0   12385.0     0          missed   \n",
       "\n",
       "   pellet_delivery  pellet_detected  \n",
       "0           2098.0           1869.0  \n",
       "1           4659.0           4283.0  \n",
       "2           6856.0           6779.0  \n",
       "3           9412.0           8999.0  \n",
       "4          12333.0          12182.0  "
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing curated xlsx\n",
    "df_added_missing_rows = pd.read_excel(xlsx_saved_file)\n",
    "df_added_missing_rows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig, backup_file_path = mouse_sessions.load_orig_xlsx_file()\n",
    "df_added_missing_rows, backup_added_rows_file_path = mouse_sessions.load_added_rows_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading orginal_df for reach events from --> G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\reach10_20250426_session001\\reach_curator_direct_backup\\20250426_christielab_session001.xlsx\n",
      "loading df with missing rows added from--> G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie-2025-04-21\\Grant_curate\\xlsx_backups\\reach10_20250426_session001\\added_missing_rows_backup\\20250426_christielab_session001.xlsx\n",
      "\n",
      "Original reach events: 52\n",
      "Added reach events: 57\n",
      "\n",
      "❌ Reaches Missed: 5\n"
     ]
    }
   ],
   "source": [
    "orig_reach_count = df_orig.shape[0]\n",
    "added_row_count = df_added_missing_rows.shape[0]\n",
    "print(f'loading orginal_df for reach events from --> {backup_file_path}')\n",
    "print(f'loading df with missing rows added from--> {backup_added_rows_file_path}')\n",
    "# Count the number of reach events\n",
    "print('')\n",
    "print(f\"Original reach events: {len(df_orig)}\")\n",
    "print(f\"Added reach events: {len(df_added_missing_rows)}\")\n",
    "print('')\n",
    "print(f'❌ Reaches Missed: {added_row_count- orig_reach_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>ReachType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1816</td>\n",
       "      <td>2100</td>\n",
       "      <td>2185</td>\n",
       "      <td>2202</td>\n",
       "      <td>2205</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>2098</td>\n",
       "      <td>1869</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229</td>\n",
       "      <td>4661</td>\n",
       "      <td>4664</td>\n",
       "      <td>4689</td>\n",
       "      <td>4701</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>4659</td>\n",
       "      <td>4283</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6725</td>\n",
       "      <td>6858</td>\n",
       "      <td>6873</td>\n",
       "      <td>6889</td>\n",
       "      <td>6918</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>6856</td>\n",
       "      <td>6779</td>\n",
       "      <td>on_pellet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8911</td>\n",
       "      <td>9414</td>\n",
       "      <td>9428</td>\n",
       "      <td>9448</td>\n",
       "      <td>9459</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>9412</td>\n",
       "      <td>8999</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12129</td>\n",
       "      <td>12336</td>\n",
       "      <td>12353</td>\n",
       "      <td>12374</td>\n",
       "      <td>12385</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>12333</td>\n",
       "      <td>12182</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14405</td>\n",
       "      <td>14795</td>\n",
       "      <td>14810</td>\n",
       "      <td>14833</td>\n",
       "      <td>14855</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>14793</td>\n",
       "      <td>14492</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16892</td>\n",
       "      <td>17207</td>\n",
       "      <td>17221</td>\n",
       "      <td>17240</td>\n",
       "      <td>17245</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>17205</td>\n",
       "      <td>16978</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19305</td>\n",
       "      <td>19441</td>\n",
       "      <td>19451</td>\n",
       "      <td>19464</td>\n",
       "      <td>19472</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>19439</td>\n",
       "      <td>19362</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23610</td>\n",
       "      <td>24047</td>\n",
       "      <td>24060</td>\n",
       "      <td>24080</td>\n",
       "      <td>24086</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>24044</td>\n",
       "      <td>23664</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28216</td>\n",
       "      <td>28351</td>\n",
       "      <td>28367</td>\n",
       "      <td>28381</td>\n",
       "      <td>28384</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>28349</td>\n",
       "      <td>28273</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32525</td>\n",
       "      <td>32813</td>\n",
       "      <td>32821</td>\n",
       "      <td>32832</td>\n",
       "      <td>32841</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>32811</td>\n",
       "      <td>32582</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36972</td>\n",
       "      <td>37252</td>\n",
       "      <td>37263</td>\n",
       "      <td>37277</td>\n",
       "      <td>37287</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>37250</td>\n",
       "      <td>37061</td>\n",
       "      <td>on_pellet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39311</td>\n",
       "      <td>39674</td>\n",
       "      <td>39697</td>\n",
       "      <td>39712</td>\n",
       "      <td>39717</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>39672</td>\n",
       "      <td>39365</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43848</td>\n",
       "      <td>44324</td>\n",
       "      <td>44333</td>\n",
       "      <td>44342</td>\n",
       "      <td>44359</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>44322</td>\n",
       "      <td>43939</td>\n",
       "      <td>on_pellet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46399</td>\n",
       "      <td>46675</td>\n",
       "      <td>46685</td>\n",
       "      <td>46694</td>\n",
       "      <td>46703</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>46673</td>\n",
       "      <td>46485</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    T6000  T5000  reachInit  reachMax  reachEnd  stim       behaviors  \\\n",
       "0    1816   2100       2185      2202      2205     0          missed   \n",
       "1    4229   4661       4664      4689      4701     0         dropped   \n",
       "2    6725   6858       6873      6889      6918     0  consumed_first   \n",
       "3    8911   9414       9428      9448      9459     0          missed   \n",
       "4   12129  12336      12353     12374     12385     0          missed   \n",
       "5   14405  14795      14810     14833     14855     0  consumed_first   \n",
       "6   16892  17207      17221     17240     17245     0         dropped   \n",
       "7   19305  19441      19451     19464     19472     0          missed   \n",
       "8   23610  24047      24060     24080     24086     0         dropped   \n",
       "9   28216  28351      28367     28381     28384     0         dropped   \n",
       "10  32525  32813      32821     32832     32841     0         dropped   \n",
       "11  36972  37252      37263     37277     37287     0  consumed_first   \n",
       "12  39311  39674      39697     39712     39717     0         dropped   \n",
       "13  43848  44324      44333     44342     44359     0  consumed_first   \n",
       "14  46399  46675      46685     46694     46703     0          missed   \n",
       "\n",
       "    pellet_delivery  pellet_detected  ReachType  \n",
       "0              2098             1869      short  \n",
       "1              4659             4283      short  \n",
       "2              6856             6779  on_pellet  \n",
       "3              9412             8999      short  \n",
       "4             12333            12182      short  \n",
       "5             14793            14492      above  \n",
       "6             17205            16978      short  \n",
       "7             19439            19362      short  \n",
       "8             24044            23664      above  \n",
       "9             28349            28273      above  \n",
       "10            32811            32582      short  \n",
       "11            37250            37061  on_pellet  \n",
       "12            39672            39365      above  \n",
       "13            44322            43939  on_pellet  \n",
       "14            46673            46485       left  "
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1816</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229</td>\n",
       "      <td>4661.0</td>\n",
       "      <td>4664.0</td>\n",
       "      <td>4689.0</td>\n",
       "      <td>4701.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>4659.0</td>\n",
       "      <td>4283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6725</td>\n",
       "      <td>6858.0</td>\n",
       "      <td>6873.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>6918.0</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>6856.0</td>\n",
       "      <td>6779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8911</td>\n",
       "      <td>9414.0</td>\n",
       "      <td>9428.0</td>\n",
       "      <td>9448.0</td>\n",
       "      <td>9459.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>9412.0</td>\n",
       "      <td>8999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12129</td>\n",
       "      <td>12336.0</td>\n",
       "      <td>12353.0</td>\n",
       "      <td>12374.0</td>\n",
       "      <td>12385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>12333.0</td>\n",
       "      <td>12182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14405</td>\n",
       "      <td>14795.0</td>\n",
       "      <td>14810.0</td>\n",
       "      <td>14833.0</td>\n",
       "      <td>14855.0</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>14793.0</td>\n",
       "      <td>14492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16892</td>\n",
       "      <td>17207.0</td>\n",
       "      <td>17221.0</td>\n",
       "      <td>17240.0</td>\n",
       "      <td>17245.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>17205.0</td>\n",
       "      <td>16978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19305</td>\n",
       "      <td>19441.0</td>\n",
       "      <td>19451.0</td>\n",
       "      <td>19464.0</td>\n",
       "      <td>19472.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>19439.0</td>\n",
       "      <td>19362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23610</td>\n",
       "      <td>24047.0</td>\n",
       "      <td>24060.0</td>\n",
       "      <td>24080.0</td>\n",
       "      <td>24086.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>24044.0</td>\n",
       "      <td>23664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28216</td>\n",
       "      <td>28351.0</td>\n",
       "      <td>28367.0</td>\n",
       "      <td>28381.0</td>\n",
       "      <td>28384.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>28349.0</td>\n",
       "      <td>28273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32525</td>\n",
       "      <td>32813.0</td>\n",
       "      <td>32821.0</td>\n",
       "      <td>32832.0</td>\n",
       "      <td>32841.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>32811.0</td>\n",
       "      <td>32582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36972</td>\n",
       "      <td>37252.0</td>\n",
       "      <td>37263.0</td>\n",
       "      <td>37277.0</td>\n",
       "      <td>37287.0</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>37250.0</td>\n",
       "      <td>37061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39311</td>\n",
       "      <td>39674.0</td>\n",
       "      <td>39697.0</td>\n",
       "      <td>39712.0</td>\n",
       "      <td>39717.0</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>39672.0</td>\n",
       "      <td>39365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43848</td>\n",
       "      <td>44324.0</td>\n",
       "      <td>44333.0</td>\n",
       "      <td>44342.0</td>\n",
       "      <td>44359.0</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_first</td>\n",
       "      <td>44322.0</td>\n",
       "      <td>43939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46399</td>\n",
       "      <td>46675.0</td>\n",
       "      <td>46685.0</td>\n",
       "      <td>46694.0</td>\n",
       "      <td>46703.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>46673.0</td>\n",
       "      <td>46485.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    T6000    T5000  reachInit  reachMax  reachEnd  stim       behaviors  \\\n",
       "0    1816   2100.0     2185.0    2202.0    2205.0     0          missed   \n",
       "1    4229   4661.0     4664.0    4689.0    4701.0     0         dropped   \n",
       "2    6725   6858.0     6873.0    6889.0    6918.0     0  consumed_first   \n",
       "3    8911   9414.0     9428.0    9448.0    9459.0     0          missed   \n",
       "4   12129  12336.0    12353.0   12374.0   12385.0     0          missed   \n",
       "5   14405  14795.0    14810.0   14833.0   14855.0     0  consumed_first   \n",
       "6   16892  17207.0    17221.0   17240.0   17245.0     0         dropped   \n",
       "7   19305  19441.0    19451.0   19464.0   19472.0     0          missed   \n",
       "8   23610  24047.0    24060.0   24080.0   24086.0     0         dropped   \n",
       "9   28216  28351.0    28367.0   28381.0   28384.0     0         dropped   \n",
       "10  32525  32813.0    32821.0   32832.0   32841.0     0         dropped   \n",
       "11  36972  37252.0    37263.0   37277.0   37287.0     0  consumed_first   \n",
       "12  39311  39674.0    39697.0   39712.0   39717.0     0         dropped   \n",
       "13  43848  44324.0    44333.0   44342.0   44359.0     0  consumed_first   \n",
       "14  46399  46675.0    46685.0   46694.0   46703.0     0          missed   \n",
       "\n",
       "    pellet_delivery  pellet_detected  \n",
       "0            2098.0           1869.0  \n",
       "1            4659.0           4283.0  \n",
       "2            6856.0           6779.0  \n",
       "3            9412.0           8999.0  \n",
       "4           12333.0          12182.0  \n",
       "5           14793.0          14492.0  \n",
       "6           17205.0          16978.0  \n",
       "7           19439.0          19362.0  \n",
       "8           24044.0          23664.0  \n",
       "9           28349.0          28273.0  \n",
       "10          32811.0          32582.0  \n",
       "11          37250.0          37061.0  \n",
       "12          39672.0          39365.0  \n",
       "13          44322.0          43939.0  \n",
       "14          46673.0          46485.0  "
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_added_missing_rows.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

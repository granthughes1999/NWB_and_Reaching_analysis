{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is to take the .xlsx file created by reach_Curator_py38_v3.py script, and adds in the missing rows for T6000, T5000 values\n",
    "- has multiple steps\n",
    "1. Backs up the raw .xlsx file created by Reach_Curator_py38_v3.py\n",
    "2. Takes raw .xlsx file created by Reach_Curator_py38_v3.py --> Adds in missing rows by reading _events.txt file and comparing it --> puts this modifed version with added rows in the root folder Grant_curate\n",
    "3. Once you have manually curated the session (ie. added reaches) using the Reach_Curator_py38_v3.py\n",
    "4. this will back up that manually curated .xlsx file into this folder, which it creates if it does not exist already --> completed_manual_curation_backup\n",
    "5. finally, it will remove any rows that have no values for ReachInit > ReachMax > ReachEnd_ --> it will then put this final cleaned version back into the root folder that the Reach_Curator_py38_v3.py saves and reads from --> Grant_curate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⭐ What this file does ⭐\n",
    "\n",
    "## ✅ Results of running this file\n",
    "1. you have created a duplicate of the .xlsx file that the reach_curator_py38_v3.py makes when you load in a session for the first time \n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/reach_curator_direct_backup\n",
    "    - Note, this file is missing all the T6000 and T5000 rows that the find_reach_events.ipynb did not associate a reach too\n",
    "2. you have created a new .xlsx file that now containes every sinlge row, meaning it added rows for every single T6000 > T5000, and left the reachInit > reachMax > reachEnd vlaues empty, this way you can manually go into the curator and add reaches for these rows\n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/added_missing_rows_backup\n",
    "\n",
    "    \n",
    "### ✅ Next Steps after running this file\n",
    "1. Go back to reach_Curator_p38_v3.py, and simply launch it liuke normal. then manually place all the reaches you need \n",
    "\n",
    "2. Once 100% done adding reachs and label. open the analyze_curated_reach_results.ipynb file (its in the same folder as this notebook)\n",
    "    - then simply run that file\n",
    "    - it will first back up your manaual curation .xlsx file too --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/completed_manual_curation_backup\n",
    "    - it will extract / drop all empty rows from that .xlsx file and save the final version too -->  Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/final_backup\n",
    "    - and it will save this final_df to the root folder, so the reach_curator can load it in --> Grant_curate/final_xlsx_file.xlsx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify these three variables as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250501_session001\n"
     ]
    }
   ],
   "source": [
    "root_path = r'G:\\Grant\\behavior_data\\DLC_net' # change this to your root path where all the analysis folder live, i currently use is G:\\Grant\\behavior_data\\DLC_net\n",
    "root_folder = 'grant_reach10_swingDoor-christie' # change this to your root folder for one specfic mouse (this should contain multiple sessions)\n",
    "\n",
    "\n",
    "# Set the specific mouse session to analyze\n",
    "session_options = ['20250421_session001', '20250424_session001', '20250426_session001','20250429_session003','20250501_session001']\n",
    "\n",
    "session_info = session_options[-1] # change this to the session you want to analyze\n",
    "print(session_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new session_option for each session\n",
    "- class that lets you load data for specific mouse sesssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_path: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\n",
      "mouse_info: {'mouse': 'reach10', 'session_date': '20250501', 'session_ID': 'session001'}\n",
      "xlsx_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\20250501_christielab_session001.xlsx\n"
     ]
    }
   ],
   "source": [
    "main_path = rf'{root_path}\\{root_folder}'\n",
    "print(f'main_path: {main_path}')\n",
    "\n",
    "class select_mouse_session:\n",
    "    def __init__(self, mouse, session_date, session_ID):\n",
    "        self.mouse = mouse\n",
    "        self.session_date = session_date\n",
    "        self.session_ID = session_ID\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Mouse: {self.mouse}, Session Date: {self.session_date}, Session ID: {self.session_ID}\"\n",
    "    \n",
    "    def get_mouse_session_files(self):\n",
    "        mouse_session = f\"{self.mouse}_{self.session_date}_{self.session_ID}\"\n",
    "        xlsx_file = rf'{main_path}\\Grant_curate\\{self.session_date}_christielab_{self.session_ID}.xlsx'\n",
    "        txt_file = rf\"{main_path}\\videos\\{self.session_date}\\christielab\\{self.session_ID}\\{self.session_date}_christielab_{self.session_ID}_events_shifted.txt\"\n",
    "        xlsx_orig = rf'{main_path}\\Grant_curate\\xlsx_backups\\curator_direct_backup\\{self.session_date}_christielab_{self.session_ID}.xlsx'\n",
    "        \n",
    "        return xlsx_file, txt_file, xlsx_orig\n",
    "    \n",
    "    def get_mouse_info(self):\n",
    "        mouse_info = {\n",
    "            'mouse': self.mouse,\n",
    "            'session_date': self.session_date,\n",
    "            'session_ID': self.session_ID\n",
    "        }\n",
    "        return mouse_info\n",
    "    \n",
    "\n",
    "# Strip the session info to get the session date and ID\n",
    "session_date = session_info.split('_')[0]\n",
    "session_ID = session_info.split('_')[1]\n",
    "\n",
    "# Strip the mouse name from the root folder\n",
    "mouse = root_folder.split('_')[1]\n",
    "\n",
    "# Create an instance of the class with the mouse name, session date, and session ID\n",
    "class_intsance = select_mouse_session(mouse='reach10', session_date=session_date, session_ID=session_ID)\n",
    "\n",
    "# Get the mouse session files and info\n",
    "xlsx_file, txt_file, xlsx_orig = class_intsance.get_mouse_session_files()\n",
    "mouse_info = class_intsance.get_mouse_info()\n",
    "\n",
    "# Print the results\n",
    "print(f'mouse_info: {mouse_info}')\n",
    "print(f'xlsx_file: {xlsx_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "session_save_name: reach10_20250501_session001\n",
      "\n",
      "mouse: reach10\n",
      "session_date: 20250501\n",
      "session_ID: session001\n",
      "original_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\n",
      "backup_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach10_20250501_session001\\reach_curator_direct_backup\n"
     ]
    }
   ],
   "source": [
    "session_date = mouse_info['session_date']\n",
    "session_ID = mouse_info['session_ID']\n",
    "mouse = mouse_info['mouse']\n",
    "session_save_name = f\"{mouse}_{session_date}_{session_ID}\"\n",
    "print('=========================')\n",
    "print(f'session_save_name: {session_save_name}')\n",
    "print('')\n",
    "print(f'mouse: {mouse}')\n",
    "print(f'session_date: {session_date}')\n",
    "print(f'session_ID: {session_ID}')\n",
    "\n",
    "\n",
    "    # ---- Step 1: Make a backup in curator_backup folder\n",
    "original_dir = os.path.dirname(xlsx_file)\n",
    "backup_dir = os.path.join(original_dir, 'xlsx_backups',session_save_name,'reach_curator_direct_backup')\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "print(f'original_dir: {original_dir}')\n",
    "print(f'backup_dir: {backup_dir}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if you have already analyzed this session\n",
    "- if you have, the code is going to stop you from re-analyzing it by KILLING the keneral\n",
    "- you you do want to overwrite these files --> you need to re-run from the top and skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_df_backup = os.path.join(os.path.dirname(xlsx_file), 'xlsx_backups',session_save_name ,'final_backup')\n",
    "final_df_backup_file_path = os.path.join(final_df_backup, os.path.basename(xlsx_file))\n",
    "\n",
    "manual_curation_backup = os.path.join(os.path.dirname(xlsx_file),'xlsx_backups', session_save_name,'completed_manual_curation_backup')\n",
    "manual_curation_backup = os.path.join(manual_curation_backup, os.path.basename(xlsx_file))\n",
    "\n",
    "if os.path.exists(manual_curation_backup):\n",
    "    print('⚠️ Looks like you have already completed the manual curation for this session ⚠️')\n",
    "    print('❌ Therefore, in an effort to prevent overwriting any files, the script changed is going to KILL the kernal (sorry)❌')\n",
    "    print('')\n",
    "    print(f'manual_curation_backup: {manual_curation_backup}')\n",
    "    print('')\n",
    "    print('===========================================')\n",
    "    print(' ✅ if you actually want to run this script on this session then simply skip running this cell next time ✅')\n",
    "    print('===========================================')\n",
    "    exit()\n",
    "\n",
    "print('')\n",
    "if os.path.exists(final_df_backup_file_path):\n",
    "    print('⚠️ Looks like you have already completed the final curation for this session ⚠️')\n",
    "    print('❌ Therefore, in an effort to prevent overwriting any files, the script changed is going to KILL the kernal (sorry)❌')\n",
    "    print('')\n",
    "    print(f'final_df_backup_file_path: {final_df_backup_file_path}')\n",
    "    print('')\n",
    "    print('===========================================')\n",
    "    print(' ✅ if you actually want to run this script on this session then simply skip running this cell next time ✅')\n",
    "    print('===========================================')    \n",
    "    exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify existence of session files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️Warning: Backup file already exists at G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach10_20250501_session001\\reach_curator_direct_backup\\20250501_christielab_session001.xlsx⚠️\n",
      "\n",
      "backup_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach10_20250501_session001\\reach_curator_direct_backup\\20250501_christielab_session001.xlsx\n",
      "=========================\n",
      "xlsx_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\20250501_christielab_session001.xlsx\n",
      "=========================\n",
      "txt_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\videos\\20250501\\christielab\\session001\\20250501_christielab_session001_events_shifted.txt\n",
      "=========================\n",
      "xlsx_orig: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\curator_direct_backup\\20250501_christielab_session001.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(txt_file):\n",
    "    print(f\"⚠️Warning: {txt_file} does not exist⚠️\")\n",
    "\n",
    "backup_file_path = os.path.join(backup_dir, os.path.basename(xlsx_file))\n",
    "if os.path.exists(backup_file_path):\n",
    "    print(f\"⚠️Warning: Backup file already exists at {backup_file_path}⚠️\")\n",
    "    print('')\n",
    "else:\n",
    "        # Check if files exist\n",
    "    if not os.path.exists(xlsx_file):\n",
    "        print(f\"⚠️Warning: {xlsx_file} does not exist⚠️\")\n",
    "    else:\n",
    "        # Copy the original file to the backup directory\n",
    "        shutil.copy2(xlsx_file, backup_file_path)\n",
    "        print(f\"✅ Backup saved to: {backup_file_path}\")\n",
    "\n",
    "# ---- (your parsing & merging code goes here)\n",
    "# ... your code to build `combined` DataFrame ...\n",
    "\n",
    "print(f'backup_dir: {backup_file_path}')\n",
    "print('=========================')\n",
    "print(f'xlsx_file: {xlsx_file}')\n",
    "print('=========================')\n",
    "print(f'txt_file: {txt_file}')\n",
    "print('=========================')\n",
    "print(f'xlsx_orig: {xlsx_orig}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the cell that takes the .xlsx file and the .txt file and creates a new .xlsx file with the manual additions\n",
    "- makes a new folder called manual_additions if it does not exist\n",
    "- reads the .xlsx file into a pandas dataframe\n",
    "- reads the .txt file into a pandas dataframe\n",
    "- creates a new dataframe with the manual additions\n",
    "- saves the new dataframe to a new .xlsx file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing xlsx file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\20250501_christielab_session001.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>Reach_type</th>\n",
       "      <th>behaviors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8689</td>\n",
       "      <td>8711</td>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "      <td>8679</td>\n",
       "      <td>8378</td>\n",
       "      <td>8317</td>\n",
       "      <td>8681</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17625</td>\n",
       "      <td>17644</td>\n",
       "      <td>17693</td>\n",
       "      <td>0</td>\n",
       "      <td>17604</td>\n",
       "      <td>17300</td>\n",
       "      <td>17228</td>\n",
       "      <td>17607</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20646</td>\n",
       "      <td>20659</td>\n",
       "      <td>20742</td>\n",
       "      <td>0</td>\n",
       "      <td>20628</td>\n",
       "      <td>20552</td>\n",
       "      <td>20488</td>\n",
       "      <td>20630</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23112</td>\n",
       "      <td>23132</td>\n",
       "      <td>23135</td>\n",
       "      <td>0</td>\n",
       "      <td>23086</td>\n",
       "      <td>22935</td>\n",
       "      <td>22874</td>\n",
       "      <td>23089</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26169</td>\n",
       "      <td>26206</td>\n",
       "      <td>26267</td>\n",
       "      <td>0</td>\n",
       "      <td>26145</td>\n",
       "      <td>25729</td>\n",
       "      <td>25668</td>\n",
       "      <td>26147</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reachInit  reachMax  reachEnd  stim  pellet_delivery  pellet_detected  \\\n",
       "0       8689      8711      8714     0             8679             8378   \n",
       "1      17625     17644     17693     0            17604            17300   \n",
       "2      20646     20659     20742     0            20628            20552   \n",
       "3      23112     23132     23135     0            23086            22935   \n",
       "4      26169     26206     26267     0            26145            25729   \n",
       "\n",
       "   T6000  T5000  Reach_type behaviors  \n",
       "0   8317   8681           0   grabbed  \n",
       "1  17228  17607           0   stalled  \n",
       "2  20488  20630           0   stalled  \n",
       "3  22874  23089           0    missed  \n",
       "4  25668  26147           0   stalled  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing curated xlsx\n",
    "print(f\"Loading existing xlsx file: {xlsx_file}\")\n",
    "df_orig = pd.read_excel(xlsx_file)\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class modify_curator_xlsx_file(object):\n",
    "    def __init__(self, xlsx_file, txt_file,save_df=True):\n",
    "        self.txt_file = txt_file\n",
    "        self.xlsx_file = xlsx_file\n",
    "        self.save_df = save_df\n",
    "\n",
    "        \n",
    "    def create_new_xlxs_file(self):\n",
    "        save_df = self.save_df\n",
    "        # Load the existing xlsx file\n",
    "        df_orig = pd.read_excel(self.xlsx_file)\n",
    "        # Check if the file is empty\n",
    "        txt_file = self.txt_file\n",
    "        if not os.path.exists(txt_file):\n",
    "            print(f\"⚠️Warning: {txt_file} does not exist⚠️\")\n",
    "            return None\n",
    "        # Check if the xlsx file is empty\n",
    "        xlsx_file = self.xlsx_file\n",
    "        if not os.path.exists(xlsx_file):\n",
    "            print(f\"⚠️Warning: {xlsx_file} does not exist⚠️\")\n",
    "            return None\n",
    "\n",
    "        if df_orig.empty:\n",
    "            print(\"⚠️Warning: The xlsx file is empty⚠️\")\n",
    "            return None\n",
    "        \n",
    "        # Normalize column names just in case\n",
    "        df_orig.columns = df_orig.columns.str.strip()\n",
    "\n",
    "        # Load and parse txt as done earlier\n",
    "        events = []\n",
    "        current_event = {}\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    key, value = line.strip().split('\\t')\n",
    "                    value = int(value)\n",
    "                    if key == 'T6000_played':\n",
    "                        if current_event:\n",
    "                            events.append(current_event)\n",
    "                        current_event = {'T6000': value}\n",
    "                    elif key == 'pellet_detected':\n",
    "                        current_event['pellet_detected'] = value\n",
    "                    elif key == 'pellet_delivery':\n",
    "                        current_event['pellet_delivery'] = value\n",
    "                    elif key == 'T5000_played':\n",
    "                        current_event['T5000'] = value\n",
    "        if current_event:\n",
    "            events.append(current_event)\n",
    "\n",
    "        events_df = pd.DataFrame(events)\n",
    "\n",
    "        # Find which T6000s are missing from original file\n",
    "        existing_T6000s = df_orig['T6000'].values\n",
    "        new_rows = events_df[~events_df['T6000'].isin(existing_T6000s)].copy()\n",
    "\n",
    "        # Fill in missing columns to match structure\n",
    "        new_rows['reachInit'] = np.nan\n",
    "        new_rows['reachMax'] = np.nan\n",
    "        new_rows['reachEnd'] = np.nan\n",
    "        new_rows['stim'] = 0\n",
    "        new_rows['behaviors'] = np.nan\n",
    "\n",
    "        # # Reorder columns to match original file\n",
    "        # new_rows = new_rows[['reachinit', 'reachmax', 'reachend', 'stim',\n",
    "        #                      'pellet_delivery', 'pellet_detected', 't6000', 't5000', 'behaviors']]\n",
    "\n",
    "        # Reorder columns to match original file\n",
    "        new_rows = new_rows[['T6000', 'T5000', 'reachInit', 'reachMax',\n",
    "                            'reachEnd', 'stim','behaviors' ,'pellet_delivery', 'pellet_detected']]\n",
    "\n",
    "        # Combine and sort by T6000\n",
    "        combined = pd.concat([df_orig, new_rows], ignore_index=True)\n",
    "        combined = combined.sort_values(by='T6000').reset_index(drop=True)\n",
    "\n",
    "        # Force final column order\n",
    "        combined = combined[['T6000', 'T5000', 'reachInit', 'reachMax',\n",
    "                            'reachEnd', 'stim', 'behaviors',\n",
    "                            'pellet_delivery', 'pellet_detected']]\n",
    "\n",
    "\n",
    "        # ---- Step 2: Save output as the same original file (overwrite it)\n",
    "        xlsx_save_path = xlsx_file\n",
    "        self.xlsx_file = xlsx_save_path\n",
    "\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_dir = os.path.join(original_dir,'xlsx_backups',session_save_name ,'reach_curator_direct_backup')\n",
    "        backup_file_path = os.path.join(backup_dir, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        backup_added_rows = os.path.join(original_dir, 'xlsx_backups' ,session_save_name,'added_missing_rows_backup')\n",
    "        os.makedirs(backup_added_rows, exist_ok=True)\n",
    "        backup_added_rows_file_path = os.path.join(backup_added_rows, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        # Save the combined DataFrame to the same xlsx file\n",
    "        if save_df:\n",
    "            if os.path.exists(backup_file_path):\n",
    "                combined.to_excel(xlsx_save_path, index=False)\n",
    "                combined.to_excel(backup_added_rows_file_path, index=False)\n",
    "                print(f\"✅ Final merged Excel saved to: {xlsx_save_path}\")\n",
    "                print(f\"✅ Backup saved to: {backup_added_rows_file_path}\")\n",
    "                return combined, xlsx_save_path\n",
    "            else:\n",
    "                print(f\"⚠️Warning: Backup file doesnt exists⚠️\")\n",
    "                print('❌ Stopping the script to avoid overwriting the xlsx file without a back up❌')\n",
    "                print(f\"⚠️Warning: {backup_file_path} does not exist⚠️\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(f\"⚠️Warning: DataFrame not saved to {xlsx_save_path}⚠️\")\n",
    "            print('set save_df to True to save the DataFrame')\n",
    "            return combined\n",
    "    \n",
    "\n",
    "    def drop_empty_reach_rows(self):\n",
    "      \n",
    "        df = pd.read_excel(self.xlsx_file)\n",
    "        # back up the newly created xlsx file\n",
    "        backup_dir_02 = os.path.join(os.path.dirname(self.xlsx_file),'xlsx_backups', session_save_name,'completed_manual_curation_backup')\n",
    "        os.makedirs(backup_dir_02, exist_ok=True)\n",
    "        backup_file_path_02 = os.path.join(backup_dir_02, os.path.basename(self.xlsx_file))\n",
    "        if os.path.exists(backup_file_path_02):\n",
    "            print(f\"⚠️Warning: Backup file already exists at {backup_file_path_02}⚠️\")\n",
    "            print('❌ Stopping the script to avoid overwriting the backup file ❌')\n",
    "            return None \n",
    "        else:\n",
    "            # Copy the original file to the backup directory\n",
    "            shutil.copy2(self.xlsx_file, backup_file_path_02)\n",
    "            print(f\"✅ Backup saved to: {backup_file_path_02}\")\n",
    "        \"\"\"\n",
    "        Drop specified rows from the DataFrame.\n",
    "        \"\"\"\n",
    "        # Drop bad rows\n",
    "        df = df.dropna(subset=['reachInit']).reset_index(drop=True)\n",
    "         # save the DataFrame to the same xlsx file\n",
    "        if self.save_df:\n",
    "            df.to_excel(self.xlsx_file, index=False)\n",
    "            print(f\"✅ Final merged Excel saved to: {self.xlsx_file}\")   \n",
    "              \n",
    "        return df\n",
    "    \n",
    "    def load_orig_xlsx_file(self):\n",
    "        \"\"\"\n",
    "        Load the original xlsx file.\n",
    "        \"\"\"\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_dir = os.path.join(original_dir, 'xlsx_backups',session_save_name ,'reach_curator_direct_backup')\n",
    "        backup_file_path = os.path.join(backup_dir, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        df_orig = pd.read_excel(backup_file_path)\n",
    "        return df_orig, backup_file_path\n",
    "    \n",
    "    def load_added_rows_xlsx(self):\n",
    "        \"\"\"\n",
    "        Load the added rows xlsx file.\n",
    "        \"\"\"\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_added_rows = os.path.join(original_dir,'xlsx_backups' ,session_save_name, 'added_missing_rows_backup')\n",
    "        backup_added_rows_file_path = os.path.join(backup_added_rows, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        df_added_rows = pd.read_excel(backup_added_rows_file_path)\n",
    "        return df_added_rows, backup_added_rows_file_path\n",
    "    \n",
    "    \n",
    "    def load_final_xlsx(self):\n",
    "        \"\"\"\n",
    "        Load the combined xlsx file.\n",
    "        \"\"\"\n",
    "        df_final = pd.read_excel(self.xlsx_file)\n",
    "        return df_final, self.xlsx_file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_fail_modify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final merged Excel saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\20250501_christielab_session001.xlsx\n",
      "✅ Backup saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach10_20250501_session001\\added_missing_rows_backup\\20250501_christielab_session001.xlsx\n"
     ]
    }
   ],
   "source": [
    "if safe_fail_modify:\n",
    "    mouse_sessions = modify_curator_xlsx_file(xlsx_file, txt_file,save_df=True)\n",
    "    df_modied, xlsx_saved_file = mouse_sessions.create_new_xlxs_file()\n",
    "    df_orig, xlsx_orig_file = mouse_sessions.load_orig_xlsx_file()\n",
    "    df_added_rows, xlsx_added_rows_file = mouse_sessions.load_added_rows_xlsx()\n",
    "    df_final, xlsx_final_file = mouse_sessions.load_final_xlsx()\n",
    "    df_modied\n",
    "else:\n",
    "    print(f\"⚠️Warning: safe_fail actviated⚠️\")\n",
    "    print('if you want to run the code, please re-run this cell')\n",
    "    print('Note this ')\n",
    "    safe_fail_modify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1805</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5938</td>\n",
       "      <td>6232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>6004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8317</td>\n",
       "      <td>8681.0</td>\n",
       "      <td>8689.0</td>\n",
       "      <td>8711.0</td>\n",
       "      <td>8714.0</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12505</td>\n",
       "      <td>12725.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12723.0</td>\n",
       "      <td>12569.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T6000    T5000  reachInit  reachMax  reachEnd  stim behaviors  \\\n",
       "0   1805   1952.0        NaN       NaN       NaN     0       NaN   \n",
       "1   3968      NaN        NaN       NaN       NaN     0       NaN   \n",
       "2   5938   6232.0        NaN       NaN       NaN     0       NaN   \n",
       "3   8317   8681.0     8689.0    8711.0    8714.0     0   grabbed   \n",
       "4  12505  12725.0        NaN       NaN       NaN     0       NaN   \n",
       "\n",
       "   pellet_delivery  pellet_detected  \n",
       "0           1950.0           1874.0  \n",
       "1              NaN              NaN  \n",
       "2           6230.0           6004.0  \n",
       "3           8679.0           8378.0  \n",
       "4          12723.0          12569.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing curated xlsx\n",
    "df_added_missing_rows = pd.read_excel(xlsx_saved_file)\n",
    "df_added_missing_rows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig, backup_file_path = mouse_sessions.load_orig_xlsx_file()\n",
    "df_added_missing_rows, backup_added_rows_file_path = mouse_sessions.load_added_rows_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading orginal_df for reach events from --> G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach10_20250501_session001\\reach_curator_direct_backup\\20250501_christielab_session001.xlsx\n",
      "loading df with missing rows added from--> G:\\Grant\\behavior_data\\DLC_net\\grant_reach10_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach10_20250501_session001\\added_missing_rows_backup\\20250501_christielab_session001.xlsx\n",
      "\n",
      "Original reach events: 49\n",
      "Added reach events: 84\n",
      "\n",
      "❌ Reaches Missed: 35\n"
     ]
    }
   ],
   "source": [
    "orig_reach_count = df_orig.shape[0]\n",
    "added_row_count = df_added_missing_rows.shape[0]\n",
    "print(f'loading orginal_df for reach events from --> {backup_file_path}')\n",
    "print(f'loading df with missing rows added from--> {backup_added_rows_file_path}')\n",
    "# Count the number of reach events\n",
    "print('')\n",
    "print(f\"Original reach events: {len(df_orig)}\")\n",
    "print(f\"Added reach events: {len(df_added_missing_rows)}\")\n",
    "print('')\n",
    "print(f'❌ Reaches Missed: {added_row_count- orig_reach_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>Reach_type</th>\n",
       "      <th>behaviors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8689</td>\n",
       "      <td>8711</td>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "      <td>8679</td>\n",
       "      <td>8378</td>\n",
       "      <td>8317</td>\n",
       "      <td>8681</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17625</td>\n",
       "      <td>17644</td>\n",
       "      <td>17693</td>\n",
       "      <td>0</td>\n",
       "      <td>17604</td>\n",
       "      <td>17300</td>\n",
       "      <td>17228</td>\n",
       "      <td>17607</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20646</td>\n",
       "      <td>20659</td>\n",
       "      <td>20742</td>\n",
       "      <td>0</td>\n",
       "      <td>20628</td>\n",
       "      <td>20552</td>\n",
       "      <td>20488</td>\n",
       "      <td>20630</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23112</td>\n",
       "      <td>23132</td>\n",
       "      <td>23135</td>\n",
       "      <td>0</td>\n",
       "      <td>23086</td>\n",
       "      <td>22935</td>\n",
       "      <td>22874</td>\n",
       "      <td>23089</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26169</td>\n",
       "      <td>26206</td>\n",
       "      <td>26267</td>\n",
       "      <td>0</td>\n",
       "      <td>26145</td>\n",
       "      <td>25729</td>\n",
       "      <td>25668</td>\n",
       "      <td>26147</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32944</td>\n",
       "      <td>33010</td>\n",
       "      <td>33021</td>\n",
       "      <td>0</td>\n",
       "      <td>32923</td>\n",
       "      <td>32698</td>\n",
       "      <td>32636</td>\n",
       "      <td>32925</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37480</td>\n",
       "      <td>37495</td>\n",
       "      <td>37558</td>\n",
       "      <td>0</td>\n",
       "      <td>37459</td>\n",
       "      <td>37159</td>\n",
       "      <td>37098</td>\n",
       "      <td>37462</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43918</td>\n",
       "      <td>43952</td>\n",
       "      <td>44000</td>\n",
       "      <td>0</td>\n",
       "      <td>43898</td>\n",
       "      <td>43486</td>\n",
       "      <td>43421</td>\n",
       "      <td>43901</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52136</td>\n",
       "      <td>52171</td>\n",
       "      <td>52177</td>\n",
       "      <td>0</td>\n",
       "      <td>52118</td>\n",
       "      <td>51967</td>\n",
       "      <td>51898</td>\n",
       "      <td>52121</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54303</td>\n",
       "      <td>54319</td>\n",
       "      <td>54329</td>\n",
       "      <td>0</td>\n",
       "      <td>54275</td>\n",
       "      <td>54197</td>\n",
       "      <td>54132</td>\n",
       "      <td>54277</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57809</td>\n",
       "      <td>57872</td>\n",
       "      <td>57876</td>\n",
       "      <td>0</td>\n",
       "      <td>57782</td>\n",
       "      <td>57519</td>\n",
       "      <td>57456</td>\n",
       "      <td>57784</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>61126</td>\n",
       "      <td>61171</td>\n",
       "      <td>61215</td>\n",
       "      <td>0</td>\n",
       "      <td>61105</td>\n",
       "      <td>60719</td>\n",
       "      <td>60656</td>\n",
       "      <td>61107</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74636</td>\n",
       "      <td>74654</td>\n",
       "      <td>74659</td>\n",
       "      <td>0</td>\n",
       "      <td>74621</td>\n",
       "      <td>74393</td>\n",
       "      <td>74331</td>\n",
       "      <td>74623</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83702</td>\n",
       "      <td>83787</td>\n",
       "      <td>83799</td>\n",
       "      <td>0</td>\n",
       "      <td>83687</td>\n",
       "      <td>83311</td>\n",
       "      <td>83244</td>\n",
       "      <td>83690</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90867</td>\n",
       "      <td>90874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88187</td>\n",
       "      <td>90650</td>\n",
       "      <td>90590</td>\n",
       "      <td>88190</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reachInit  reachMax  reachEnd  stim  pellet_delivery  pellet_detected  \\\n",
       "0        8689      8711      8714     0             8679             8378   \n",
       "1       17625     17644     17693     0            17604            17300   \n",
       "2       20646     20659     20742     0            20628            20552   \n",
       "3       23112     23132     23135     0            23086            22935   \n",
       "4       26169     26206     26267     0            26145            25729   \n",
       "5       32944     33010     33021     0            32923            32698   \n",
       "6       37480     37495     37558     0            37459            37159   \n",
       "7       43918     43952     44000     0            43898            43486   \n",
       "8       52136     52171     52177     0            52118            51967   \n",
       "9       54303     54319     54329     0            54275            54197   \n",
       "10      57809     57872     57876     0            57782            57519   \n",
       "11      61126     61171     61215     0            61105            60719   \n",
       "12      74636     74654     74659     0            74621            74393   \n",
       "13      83702     83787     83799     0            83687            83311   \n",
       "14      90867     90874         0     0            88187            90650   \n",
       "\n",
       "    T6000  T5000  Reach_type behaviors  \n",
       "0    8317   8681           0   grabbed  \n",
       "1   17228  17607           0   stalled  \n",
       "2   20488  20630           0   stalled  \n",
       "3   22874  23089           0    missed  \n",
       "4   25668  26147           0   stalled  \n",
       "5   32636  32925           0   stalled  \n",
       "6   37098  37462           0   stalled  \n",
       "7   43421  43901           0   stalled  \n",
       "8   51898  52121           0   grabbed  \n",
       "9   54132  54277           0   grabbed  \n",
       "10  57456  57784           0   grabbed  \n",
       "11  60656  61107           0   stalled  \n",
       "12  74331  74623           0   grabbed  \n",
       "13  83244  83690           0   stalled  \n",
       "14  90590  88190           0      none  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1805</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5938</td>\n",
       "      <td>6232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>6004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8317</td>\n",
       "      <td>8681.0</td>\n",
       "      <td>8689.0</td>\n",
       "      <td>8711.0</td>\n",
       "      <td>8714.0</td>\n",
       "      <td>0</td>\n",
       "      <td>grabbed</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12505</td>\n",
       "      <td>12725.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12723.0</td>\n",
       "      <td>12569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14767</td>\n",
       "      <td>15062.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15060.0</td>\n",
       "      <td>14829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17228</td>\n",
       "      <td>17607.0</td>\n",
       "      <td>17625.0</td>\n",
       "      <td>17644.0</td>\n",
       "      <td>17693.0</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "      <td>17604.0</td>\n",
       "      <td>17300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20488</td>\n",
       "      <td>20630.0</td>\n",
       "      <td>20646.0</td>\n",
       "      <td>20659.0</td>\n",
       "      <td>20742.0</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "      <td>20628.0</td>\n",
       "      <td>20552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22874</td>\n",
       "      <td>23089.0</td>\n",
       "      <td>23112.0</td>\n",
       "      <td>23132.0</td>\n",
       "      <td>23135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>23086.0</td>\n",
       "      <td>22935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25668</td>\n",
       "      <td>26147.0</td>\n",
       "      <td>26169.0</td>\n",
       "      <td>26206.0</td>\n",
       "      <td>26267.0</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "      <td>26145.0</td>\n",
       "      <td>25729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30306</td>\n",
       "      <td>30559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30557.0</td>\n",
       "      <td>30368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32636</td>\n",
       "      <td>32925.0</td>\n",
       "      <td>32944.0</td>\n",
       "      <td>33010.0</td>\n",
       "      <td>33021.0</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "      <td>32923.0</td>\n",
       "      <td>32698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37098</td>\n",
       "      <td>37462.0</td>\n",
       "      <td>37480.0</td>\n",
       "      <td>37495.0</td>\n",
       "      <td>37558.0</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "      <td>37459.0</td>\n",
       "      <td>37159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40789</td>\n",
       "      <td>40928.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40926.0</td>\n",
       "      <td>40849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43421</td>\n",
       "      <td>43901.0</td>\n",
       "      <td>43918.0</td>\n",
       "      <td>43952.0</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>stalled</td>\n",
       "      <td>43898.0</td>\n",
       "      <td>43486.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    T6000    T5000  reachInit  reachMax  reachEnd  stim behaviors  \\\n",
       "0    1805   1952.0        NaN       NaN       NaN     0       NaN   \n",
       "1    3968      NaN        NaN       NaN       NaN     0       NaN   \n",
       "2    5938   6232.0        NaN       NaN       NaN     0       NaN   \n",
       "3    8317   8681.0     8689.0    8711.0    8714.0     0   grabbed   \n",
       "4   12505  12725.0        NaN       NaN       NaN     0       NaN   \n",
       "5   14767  15062.0        NaN       NaN       NaN     0       NaN   \n",
       "6   17228  17607.0    17625.0   17644.0   17693.0     0   stalled   \n",
       "7   20488  20630.0    20646.0   20659.0   20742.0     0   stalled   \n",
       "8   22874  23089.0    23112.0   23132.0   23135.0     0    missed   \n",
       "9   25668  26147.0    26169.0   26206.0   26267.0     0   stalled   \n",
       "10  30306  30559.0        NaN       NaN       NaN     0       NaN   \n",
       "11  32636  32925.0    32944.0   33010.0   33021.0     0   stalled   \n",
       "12  37098  37462.0    37480.0   37495.0   37558.0     0   stalled   \n",
       "13  40789  40928.0        NaN       NaN       NaN     0       NaN   \n",
       "14  43421  43901.0    43918.0   43952.0   44000.0     0   stalled   \n",
       "\n",
       "    pellet_delivery  pellet_detected  \n",
       "0            1950.0           1874.0  \n",
       "1               NaN              NaN  \n",
       "2            6230.0           6004.0  \n",
       "3            8679.0           8378.0  \n",
       "4           12723.0          12569.0  \n",
       "5           15060.0          14829.0  \n",
       "6           17604.0          17300.0  \n",
       "7           20628.0          20552.0  \n",
       "8           23086.0          22935.0  \n",
       "9           26145.0          25729.0  \n",
       "10          30557.0          30368.0  \n",
       "11          32923.0          32698.0  \n",
       "12          37459.0          37159.0  \n",
       "13          40926.0          40849.0  \n",
       "14          43898.0          43486.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_added_missing_rows.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ END ❌\n",
    "\n",
    "\n",
    "### ✅ Next Steps\n",
    "1. Go back to reach_Curator_p38_v3.py, and simply launch it liuke normal. then manually place all the reaches you need \n",
    "\n",
    "2. Once 100% done adding reachs and label. open the analyze_curated_reach_results.ipynb file (its in the same folder as this notebook)\n",
    "    - then simply run that file\n",
    "    - it will first back up your manaual curation .xlsx file too --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/completed_manual_curation_backup\n",
    "    - it will extract / drop all empty rows from that .xlsx file and save the final version too -->  Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/final_backup\n",
    "    - and it will save this final_df to the root folder, so the reach_curator can load it in --> Grant_curate/final_xlsx_file.xlsx \n",
    "\n",
    "\n",
    "# ✅ Results of file\n",
    "1. you have created a duplicate of the .xlsx file that the reach_curator_py38_v3.py makes when you load in a session for the first time \n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/reach_curator_direct_backup\n",
    "    - Note, this file is missing all the T6000 and T5000 rows that the find_reach_events.ipynb did not associate a reach too\n",
    "2. you have created a new .xlsx file that now containes every sinlge row, meaning it added rows for every single T6000 > T5000, and left the reachInit > reachMax > reachEnd vlaues empty, this way you can manually go into the curator and add reaches for these rows\n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/added_missing_rows_backup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

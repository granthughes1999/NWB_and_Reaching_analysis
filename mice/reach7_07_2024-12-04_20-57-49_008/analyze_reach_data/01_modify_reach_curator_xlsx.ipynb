{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is to take the .xlsx file created by reach_Curator_py38_v3.py script, and adds in the missing rows for T6000, T5000 values\n",
    "- has multiple steps\n",
    "1. Backs up the raw .xlsx file created by Reach_Curator_py38_v3.py\n",
    "2. Takes raw .xlsx file created by Reach_Curator_py38_v3.py --> Adds in missing rows by reading _events.txt file and comparing it --> puts this modifed version with added rows in the root folder Grant_curate\n",
    "3. Once you have manually curated the session (ie. added reaches) using the Reach_Curator_py38_v3.py\n",
    "4. this will back up that manually curated .xlsx file into this folder, which it creates if it does not exist already --> completed_manual_curation_backup\n",
    "5. finally, it will remove any rows that have no values for ReachInit > ReachMax > ReachEnd_ --> it will then put this final cleaned version back into the root folder that the Reach_Curator_py38_v3.py saves and reads from --> Grant_curate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⭐ What this file does ⭐\n",
    "\n",
    "## ✅ Results of running this file\n",
    "1. you have created a duplicate of the .xlsx file that the reach_curator_py38_v3.py makes when you load in a session for the first time \n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/reach_curator_direct_backup\n",
    "    - Note, this file is missing all the T6000 and T5000 rows that the find_reach_events.ipynb did not associate a reach too\n",
    "2. you have created a new .xlsx file that now containes every sinlge row, meaning it added rows for every single T6000 > T5000, and left the reachInit > reachMax > reachEnd vlaues empty, this way you can manually go into the curator and add reaches for these rows\n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/added_missing_rows_backup\n",
    "\n",
    "    \n",
    "### ✅ Next Steps after running this file\n",
    "1. Go back to reach_Curator_p38_v3.py, and simply launch it liuke normal. then manually place all the reaches you need \n",
    "\n",
    "2. Once 100% done adding reachs and label. open the analyze_curated_reach_results.ipynb file (its in the same folder as this notebook)\n",
    "    - then simply run that file\n",
    "    - it will first back up your manaual curation .xlsx file too --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/completed_manual_curation_backup\n",
    "    - it will extract / drop all empty rows from that .xlsx file and save the final version too -->  Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/final_backup\n",
    "    - and it will save this final_df to the root folder, so the reach_curator can load it in --> Grant_curate/final_xlsx_file.xlsx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify these three variables as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOUSE loaded: reach7_07_2024-12-04_20-57-49_008\n",
      "DATE loaded: 20241204\n",
      "SESSION loaded: session006\n",
      "DATE_01 loaded: NA\n",
      "SESSION_01 loaded: NA\n",
      "DATE_02 loaded: NA\n",
      "SESSION_02 loaded: NA\n",
      "BEHAVIORAL_FOLDER loaded: grant_reach7_swingDoor-christie\n",
      "Recording folder found: G:\\Grant\\neuropixels\\kilosort_recordings\\reach7_07_2024-12-04_20-57-49_008\\Record Node 103\\experiment1\\recording1\\continuous\n"
     ]
    }
   ],
   "source": [
    "# Load mouse_name from .env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure that the MOUSE_NAME environment variable is set\n",
    "MOUSE = os.getenv('MOUSE')\n",
    "if MOUSE is None:\n",
    "    raise ValueError(\"MOUSE_NAME environment variable is not set. Please set it to the name of the mouse.\")\n",
    "else:\n",
    "    print(f\"MOUSE loaded: {MOUSE}\")\n",
    "\n",
    "DATE = os.getenv('DATE')\n",
    "if DATE is None:\n",
    "    raise ValueError(\"DATE environment variable is not set. Please set it to the date of the recording.\")\n",
    "else:\n",
    "    print(f\"DATE loaded: {DATE}\")\n",
    "\n",
    "SESSION = os.getenv('SESSION')\n",
    "if SESSION is None:\n",
    "    raise ValueError(\"SESSION environment variable is not set. Please set it to the session number.\")\n",
    "else:\n",
    "    print(f\"SESSION loaded: {SESSION}\")\n",
    "\n",
    "DATE_01 = os.getenv('DATE_01')\n",
    "if DATE_01 is None:\n",
    "    raise ValueError(\"DATE_01 environment variable is not set. Please set it to the date of the recording in MMDD format.\")\n",
    "else:\n",
    "    print(f\"DATE_01 loaded: {DATE_01}\")\n",
    "\n",
    "SESSION_01 = os.getenv('SESSION_01')\n",
    "if SESSION_01 is None:\n",
    "    raise ValueError(\"SESSION_01 environment variable is not set. Please set it to the session number in MMDD format.\")\n",
    "else:\n",
    "    print(f\"SESSION_01 loaded: {SESSION_01}\")\n",
    "\n",
    "DATE_02 = os.getenv('DATE_02')\n",
    "if DATE_02 is None:\n",
    "    raise ValueError(\"DATE_02 environment variable is not set. Please set it to the date of the recording in MMDD format.\")\n",
    "else:\n",
    "    print(f\"DATE_02 loaded: {DATE_02}\")\n",
    "\n",
    "SESSION_02 = os.getenv('SESSION_02')\n",
    "if SESSION_02 is None:\n",
    "    raise ValueError(\"SESSION_02 environment variable is not set. Please set it to the session number in MMDD format.\")\n",
    "else:\n",
    "    print(f\"SESSION_02 loaded: {SESSION_02}\")\n",
    "\n",
    "BEHAVIORAL_FOLDER = os.getenv('BEHAVIORAL_FOLDER')\n",
    "if BEHAVIORAL_FOLDER is None:\n",
    "    raise ValueError(\"BEHAVIORAL_FOLDER environment variable is not set. Please set it to the path of the behavioral recordings.\")\n",
    "else:\n",
    "    print(f\"BEHAVIORAL_FOLDER loaded: {BEHAVIORAL_FOLDER}\")\n",
    "\n",
    "# Construct the recording folder path\n",
    "root_recording_folder = fr\"G:\\Grant\\neuropixels\\kilosort_recordings\\{MOUSE}\"  # Replace with actual root path\n",
    "recording_folder = os.path.join(root_recording_folder, \"Record Node 103\", \"experiment1\", \"recording1\", \"continuous\")\n",
    "\n",
    "#root_behavior_path = fr\"G:\\Grant\\neuropixels\\behavioral_recordings\\{BEHAVIORAL_FOLDER}\"\n",
    "# Example values (replace as needed)A\n",
    "root_behavior_path = fr\"G:\\Grant\\behavior_data\\DLC_net\\{BEHAVIORAL_FOLDER}\"\n",
    "behavioral_folder = os.path.join(root_behavior_path, DATE, SESSION)\n",
    "\n",
    "# Check if the recording folder exists\n",
    "if not os.path.exists(recording_folder):\n",
    "    raise FileNotFoundError(f\"Recording folder not found: {recording_folder}\")\n",
    "else:\n",
    "    print(\"Recording folder found:\", recording_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241204_session006\n"
     ]
    }
   ],
   "source": [
    "root_path = r'G:\\Grant\\behavior_data\\DLC_net' # change this to your root path where all the analysis folder live, i currently use is G:\\Grant\\behavior_data\\DLC_net\n",
    "\n",
    "root_folder = BEHAVIORAL_FOLDER # change this to your root folder for one specfic mouse (this should contain multiple sessions)\n",
    "\n",
    "\n",
    "SESSION_OPTIONS = [f\"{DATE}_{SESSION}\", f\"{DATE_01}_{SESSION_01}\", f\"{DATE_02}_{SESSION_02}\"]\n",
    "# Set the specific mouse session to analyze\n",
    "\n",
    "session_info = SESSION_OPTIONS[0] # change this to the session you want to analyze\n",
    "print(session_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new session_option for each session\n",
    "- class that lets you load data for specific mouse sesssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_path: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\n",
      "mouse_info: {'mouse': 'reach7', 'session_date': '20241204', 'session_ID': 'session006'}\n",
      "xlsx_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\20241204_christielab_session006.xlsx\n"
     ]
    }
   ],
   "source": [
    "main_path = rf'{root_path}\\{root_folder}'\n",
    "print(f'main_path: {main_path}')\n",
    "\n",
    "class select_mouse_session:\n",
    "    def __init__(self, mouse, session_date, session_ID):\n",
    "        self.mouse = mouse\n",
    "        self.session_date = session_date\n",
    "        self.session_ID = session_ID\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Mouse: {self.mouse}, Session Date: {self.session_date}, Session ID: {self.session_ID}\"\n",
    "    \n",
    "    def get_mouse_session_files(self):\n",
    "        mouse_session = f\"{self.mouse}_{self.session_date}_{self.session_ID}\"\n",
    "        xlsx_file = rf'{main_path}\\Grant_curate\\{self.session_date}_christielab_{self.session_ID}.xlsx'\n",
    "        txt_file = rf\"{main_path}\\videos\\{self.session_date}\\christielab\\{self.session_ID}\\{self.session_date}_christielab_{self.session_ID}_events_shifted.txt\"\n",
    "        xlsx_orig = rf'{main_path}\\Grant_curate\\xlsx_backups\\curator_direct_backup\\{self.session_date}_christielab_{self.session_ID}.xlsx'\n",
    "        \n",
    "        return xlsx_file, txt_file, xlsx_orig\n",
    "    \n",
    "    def get_mouse_info(self):\n",
    "        mouse_info = {\n",
    "            'mouse': self.mouse,\n",
    "            'session_date': self.session_date,\n",
    "            'session_ID': self.session_ID\n",
    "        }\n",
    "        return mouse_info\n",
    "    \n",
    "\n",
    "# Strip the session info to get the session date and ID\n",
    "session_date = session_info.split('_')[0]\n",
    "session_ID = session_info.split('_')[1]\n",
    "\n",
    "# Strip the mouse name from the root folder\n",
    "mouse = root_folder.split('_')[1]\n",
    "\n",
    "# Create an instance of the class with the mouse name, session date, and session ID\n",
    "class_intsance = select_mouse_session(mouse=mouse, session_date=session_date, session_ID=session_ID)\n",
    "\n",
    "# Get the mouse session files and info\n",
    "xlsx_file, txt_file, xlsx_orig = class_intsance.get_mouse_session_files()\n",
    "mouse_info = class_intsance.get_mouse_info()\n",
    "\n",
    "# Print the results\n",
    "print(f'mouse_info: {mouse_info}')\n",
    "print(f'xlsx_file: {xlsx_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "session_save_name: reach7_20241204_session006\n",
      "\n",
      "mouse: reach7\n",
      "session_date: 20241204\n",
      "session_ID: session006\n",
      "original_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\n",
      "backup_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach7_20241204_session006\\reach_curator_direct_backup\n"
     ]
    }
   ],
   "source": [
    "session_date = mouse_info['session_date']\n",
    "session_ID = mouse_info['session_ID']\n",
    "mouse = mouse_info['mouse']\n",
    "session_save_name = f\"{mouse}_{session_date}_{session_ID}\"\n",
    "print('=========================')\n",
    "print(f'session_save_name: {session_save_name}')\n",
    "print('')\n",
    "print(f'mouse: {mouse}')\n",
    "print(f'session_date: {session_date}')\n",
    "print(f'session_ID: {session_ID}')\n",
    "\n",
    "\n",
    "    # ---- Step 1: Make a backup in curator_backup folder\n",
    "original_dir = os.path.dirname(xlsx_file)\n",
    "backup_dir = os.path.join(original_dir, 'xlsx_backups',session_save_name,'reach_curator_direct_backup')\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "print(f'original_dir: {original_dir}')\n",
    "print(f'backup_dir: {backup_dir}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if you have already analyzed this session\n",
    "- if you have, the code is going to stop you from re-analyzing it by KILLING the keneral\n",
    "- you you do want to overwrite these files --> you need to re-run from the top and skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Looks like you have not completed the first step for this session yet ✅\n",
      "⭐=============== Therefore you should continue running this file =======================⭐\n"
     ]
    }
   ],
   "source": [
    "final_df_backup = os.path.join(os.path.dirname(xlsx_file), 'xlsx_backups',session_save_name ,'final_backup')\n",
    "final_df_backup_file_path = os.path.join(final_df_backup, os.path.basename(xlsx_file))\n",
    "\n",
    "manual_curation_backup = os.path.join(os.path.dirname(xlsx_file),'xlsx_backups', session_save_name,'completed_manual_curation_backup')\n",
    "manual_curation_backup = os.path.join(manual_curation_backup, os.path.basename(xlsx_file))\n",
    "\n",
    "if os.path.exists(manual_curation_backup):\n",
    "    print('⚠️ Looks like you have already completed the manual curation for this session ⚠️')\n",
    "    print('❌ Therefore, in an effort to prevent overwriting any files, the script changed is going to KILL the kernal (sorry)❌')\n",
    "    print('')\n",
    "    print(f'manual_curation_backup: {manual_curation_backup}')\n",
    "    print('')\n",
    "    print('===========================================')\n",
    "    print(' ✅ if you actually want to run this script on this session then simply skip running this cell next time ✅')\n",
    "    print('===========================================')\n",
    "    exit()\n",
    "\n",
    "print('')\n",
    "if os.path.exists(final_df_backup_file_path):\n",
    "    print('⚠️ Looks like you have already completed the final curation for this session ⚠️')\n",
    "    print('❌ Therefore, in an effort to prevent overwriting any files, the script changed is going to KILL the kernal (sorry)❌')\n",
    "    print('')\n",
    "    print(f'final_df_backup_file_path: {final_df_backup_file_path}')\n",
    "    print('')\n",
    "    print('===========================================')\n",
    "    print(' ✅ if you actually want to run this script on this session then simply skip running this cell next time ✅')\n",
    "    print('===========================================')    \n",
    "    exit()\n",
    "\n",
    "print('✅ Looks like you have not completed the first step for this session yet ✅')\n",
    "print('⭐=============== Therefore you should continue running this file =======================⭐')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify existence of session files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Backup saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach7_20241204_session006\\reach_curator_direct_backup\\20241204_christielab_session006.xlsx\n",
      "backup_dir: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach7_20241204_session006\\reach_curator_direct_backup\\20241204_christielab_session006.xlsx\n",
      "=========================\n",
      "xlsx_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\20241204_christielab_session006.xlsx\n",
      "=========================\n",
      "txt_file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\videos\\20241204\\christielab\\session006\\20241204_christielab_session006_events_shifted.txt\n",
      "=========================\n",
      "xlsx_orig: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\curator_direct_backup\\20241204_christielab_session006.xlsx\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(txt_file):\n",
    "    print(f\"⚠️Warning: {txt_file} does not exist⚠️\")\n",
    "\n",
    "backup_file_path = os.path.join(backup_dir, os.path.basename(xlsx_file))\n",
    "if os.path.exists(backup_file_path):\n",
    "    print(f\"⚠️Warning: Backup file already exists at {backup_file_path}⚠️\")\n",
    "else:\n",
    "        # Check if files exist\n",
    "    if not os.path.exists(xlsx_file):\n",
    "        print(f\"⚠️Warning: {xlsx_file} does not exist⚠️\")\n",
    "    else:\n",
    "        # Copy the original file to the backup directory\n",
    "        shutil.copy2(xlsx_file, backup_file_path)\n",
    "        print(f\"✅ Backup saved to: {backup_file_path}\")\n",
    "\n",
    "# ---- (your parsing & merging code goes here)\n",
    "# ... your code to build `combined` DataFrame ...\n",
    "\n",
    "print(f'backup_dir: {backup_file_path}')\n",
    "print('=========================')\n",
    "print(f'xlsx_file: {xlsx_file}')\n",
    "print('=========================')\n",
    "print(f'txt_file: {txt_file}')\n",
    "print('=========================')\n",
    "print(f'xlsx_orig: {xlsx_orig}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the cell that takes the .xlsx file and the .txt file and creates a new .xlsx file with the manual additions\n",
    "- makes a new folder called manual_additions if it does not exist\n",
    "- reads the .xlsx file into a pandas dataframe\n",
    "- reads the .txt file into a pandas dataframe\n",
    "- creates a new dataframe with the manual additions\n",
    "- saves the new dataframe to a new .xlsx file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing xlsx file: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\20241204_christielab_session006.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>Reach_type</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>ReachType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2814</td>\n",
       "      <td>2832</td>\n",
       "      <td>2862</td>\n",
       "      <td>2827</td>\n",
       "      <td>2731</td>\n",
       "      <td>2806</td>\n",
       "      <td>2608</td>\n",
       "      <td>2733</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4973</td>\n",
       "      <td>4994</td>\n",
       "      <td>5000</td>\n",
       "      <td>4959</td>\n",
       "      <td>4906</td>\n",
       "      <td>2806</td>\n",
       "      <td>4819</td>\n",
       "      <td>4908</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5021</td>\n",
       "      <td>5043</td>\n",
       "      <td>5047</td>\n",
       "      <td>4959</td>\n",
       "      <td>4906</td>\n",
       "      <td>2806</td>\n",
       "      <td>4819</td>\n",
       "      <td>4908</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7226</td>\n",
       "      <td>7257</td>\n",
       "      <td>7260</td>\n",
       "      <td>7252</td>\n",
       "      <td>7119</td>\n",
       "      <td>7194</td>\n",
       "      <td>7033</td>\n",
       "      <td>7121</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7264</td>\n",
       "      <td>7272</td>\n",
       "      <td>7316</td>\n",
       "      <td>7252</td>\n",
       "      <td>7119</td>\n",
       "      <td>7194</td>\n",
       "      <td>7033</td>\n",
       "      <td>7121</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reachInit  reachMax  reachEnd  stim  pellet_delivery  pellet_detected  \\\n",
       "0       2814      2832      2862  2827             2731             2806   \n",
       "1       4973      4994      5000  4959             4906             2806   \n",
       "2       5021      5043      5047  4959             4906             2806   \n",
       "3       7226      7257      7260  7252             7119             7194   \n",
       "4       7264      7272      7316  7252             7119             7194   \n",
       "\n",
       "   T6000  T5000  Reach_type       behaviors ReachType  \n",
       "0   2608   2733           0         dropped     right  \n",
       "1   4819   4908           0          missed      long  \n",
       "2   4819   4908           0          missed       NaN  \n",
       "3   7033   7121           0          missed     short  \n",
       "4   7033   7121           0  consumed_retry       NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing curated xlsx\n",
    "print(f\"Loading existing xlsx file: {xlsx_file}\")\n",
    "df_orig = pd.read_excel(xlsx_file)\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class modify_curator_xlsx_file(object):\n",
    "    def __init__(self, xlsx_file, txt_file,save_df=True):\n",
    "        self.txt_file = txt_file\n",
    "        self.xlsx_file = xlsx_file\n",
    "        self.save_df = save_df\n",
    "\n",
    "        \n",
    "    def create_new_xlxs_file_v1(self):\n",
    "        save_df = self.save_df\n",
    "        # Load the existing xlsx file\n",
    "        df_orig = pd.read_excel(self.xlsx_file)\n",
    "        # Check if the file is empty\n",
    "        txt_file = self.txt_file\n",
    "        if not os.path.exists(txt_file):\n",
    "            print(f\"⚠️Warning: {txt_file} does not exist⚠️\")\n",
    "            return None\n",
    "        # Check if the xlsx file is empty\n",
    "        xlsx_file = self.xlsx_file\n",
    "        if not os.path.exists(xlsx_file):\n",
    "            print(f\"⚠️Warning: {xlsx_file} does not exist⚠️\")\n",
    "            return None\n",
    "\n",
    "        if df_orig.empty:\n",
    "            print(\"⚠️Warning: The xlsx file is empty⚠️\")\n",
    "            return None\n",
    "        \n",
    "        # Normalize column names just in case\n",
    "        df_orig.columns = df_orig.columns.str.strip()\n",
    "\n",
    "        # Load and parse txt as done earlier\n",
    "        events = []\n",
    "        current_event = {}\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    key, value = line.strip().split('\\t')\n",
    "                    value = int(value)\n",
    "                    if key == 'T6000_played':\n",
    "                        if current_event:\n",
    "                            events.append(current_event)\n",
    "                        current_event = {'T6000': value}\n",
    "                    elif key == 'pellet_detected':\n",
    "                        current_event['pellet_detected'] = value\n",
    "                    elif key == 'pellet_delivery':\n",
    "                        current_event['pellet_delivery'] = value\n",
    "                    elif key == 'T5000_played':\n",
    "                        current_event['T5000'] = value\n",
    "        if current_event:\n",
    "            events.append(current_event)\n",
    "\n",
    "        events_df = pd.DataFrame(events)\n",
    "\n",
    "        # Find which T6000s are missing from original file\n",
    "        existing_T6000s = df_orig['T6000'].values\n",
    "        new_rows = events_df[~events_df['T6000'].isin(existing_T6000s)].copy()\n",
    "\n",
    "        # Fill in missing columns to match structure\n",
    "        new_rows['reachInit'] = np.nan\n",
    "        new_rows['reachMax'] = np.nan\n",
    "        new_rows['reachEnd'] = np.nan\n",
    "        new_rows['stim'] = 0\n",
    "        new_rows['behaviors'] = np.nan\n",
    "        new_rows['ReachType'] = np.nan\n",
    "\n",
    "        # # Reorder columns to match original file\n",
    "        # new_rows = new_rows[['reachinit', 'reachmax', 'reachend', 'stim',\n",
    "        #                      'pellet_delivery', 'pellet_detected', 't6000', 't5000', 'behaviors']]\n",
    "\n",
    "        # Reorder columns to match original file\n",
    "        new_rows = new_rows[['T6000', 'T5000', 'reachInit', 'reachMax',\n",
    "                            'reachEnd', 'stim','behaviors' ,'pellet_delivery', 'pellet_detected','ReachType']]\n",
    "\n",
    "        # Combine and sort by T6000\n",
    "        combined = pd.concat([df_orig, new_rows], ignore_index=True)\n",
    "        combined = combined.sort_values(by='T6000').reset_index(drop=True)\n",
    "\n",
    "        # Force final column order\n",
    "        combined = combined[['T6000', 'T5000', 'reachInit', 'reachMax',\n",
    "                            'reachEnd', 'stim', 'behaviors',\n",
    "                            'pellet_delivery', 'pellet_detected','ReachType']]\n",
    "\n",
    "\n",
    "        # ---- Step 2: Save output as the same original file (overwrite it)\n",
    "        xlsx_save_path = xlsx_file\n",
    "        self.xlsx_file = xlsx_save_path\n",
    "\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_dir = os.path.join(original_dir,'xlsx_backups',session_save_name ,'reach_curator_direct_backup')\n",
    "        backup_file_path = os.path.join(backup_dir, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        backup_added_rows = os.path.join(original_dir, 'xlsx_backups' ,session_save_name,'added_missing_rows_backup')\n",
    "        os.makedirs(backup_added_rows, exist_ok=True)\n",
    "        backup_added_rows_file_path = os.path.join(backup_added_rows, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        # Save the combined DataFrame to the same xlsx file\n",
    "        if save_df:\n",
    "            if os.path.exists(backup_file_path):\n",
    "                combined.to_excel(xlsx_save_path, index=False)\n",
    "                combined.to_excel(backup_added_rows_file_path, index=False)\n",
    "                print(f\"✅ Final merged Excel saved to: {xlsx_save_path}\")\n",
    "                print(f\"✅ Backup saved to: {backup_added_rows_file_path}\")\n",
    "                return combined, xlsx_save_path\n",
    "            else:\n",
    "                print(f\"⚠️Warning: Backup file doesnt exists⚠️\")\n",
    "                print('❌ Stopping the script to avoid overwriting the xlsx file without a back up❌')\n",
    "                print(f\"⚠️Warning: {backup_file_path} does not exist⚠️\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(f\"⚠️Warning: DataFrame not saved to {xlsx_save_path}⚠️\")\n",
    "            print('set save_df to True to save the DataFrame')\n",
    "            return combined\n",
    "    \n",
    "    def create_new_xlxs_file(self):\n",
    "        save_df = self.save_df\n",
    "        txt_file = self.txt_file\n",
    "        xlsx_file = self.xlsx_file\n",
    "\n",
    "        # 1) Validate TXT and XLSX existence\n",
    "        if not os.path.exists(txt_file):\n",
    "            print(f\"⚠️ Warning: {txt_file} does not exist\")\n",
    "            return None, None\n",
    "        if not os.path.exists(xlsx_file):\n",
    "            print(f\"⚠️ Warning: {xlsx_file} does not exist\")\n",
    "            return None, None\n",
    "\n",
    "        # 2) Load original Excel into DataFrame\n",
    "        df_orig = pd.read_excel(xlsx_file)\n",
    "        if df_orig.empty:\n",
    "            print(\"⚠️ Warning: The xlsx file is empty\")\n",
    "            return None, None\n",
    "        df_orig.columns = df_orig.columns.str.strip()\n",
    "        # Mark all original rows\n",
    "        df_orig['Added_row'] = ''\n",
    "\n",
    "        # 3) Parse event TXT file\n",
    "        events = []\n",
    "        current_event = {}\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    key, val = line.strip().split('\\t')\n",
    "                    value = int(val)\n",
    "                    if key == 'T6000_played':\n",
    "                        if current_event:\n",
    "                            events.append(current_event)\n",
    "                        current_event = {'T6000': value}\n",
    "                    elif key == 'pellet_detected':\n",
    "                        current_event['pellet_detected'] = value\n",
    "                    elif key == 'pellet_delivery':\n",
    "                        current_event['pellet_delivery'] = value\n",
    "                    elif key == 'T5000_played':\n",
    "                        current_event['T5000'] = value\n",
    "        if current_event:\n",
    "            events.append(current_event)\n",
    "        events_df = pd.DataFrame(events)\n",
    "\n",
    "        # 4) Identify and build new rows\n",
    "        existing_T6000s = df_orig['T6000'].values\n",
    "        new_rows = events_df[~events_df['T6000'].isin(existing_T6000s)].copy()\n",
    "        # Initialize required columns\n",
    "        for col in ['reachInit','reachMax','reachEnd','behaviors','ReachType']:\n",
    "            new_rows[col] = np.nan if 'reach' in col or col in ['behaviors'] else new_rows.get(col, np.nan)\n",
    "        new_rows['stim'] = 0\n",
    "        # Flag added rows with T5000\n",
    "        new_rows['Added_row'] = new_rows['T5000']\n",
    "\n",
    "        # 5) Enforce final column order\n",
    "        cols = [\n",
    "            'T6000','T5000','Added_row',\n",
    "            'reachInit','reachMax','reachEnd',\n",
    "            'stim','behaviors','pellet_delivery',\n",
    "            'pellet_detected','ReachType'\n",
    "        ]\n",
    "        df_orig = df_orig[cols]\n",
    "        new_rows = new_rows[cols]\n",
    "\n",
    "        # 6) Combine, sort, and reset index\n",
    "        combined = pd.concat([df_orig, new_rows], ignore_index=True)\n",
    "        combined = combined.sort_values('T6000', ignore_index=True)\n",
    "\n",
    "        # 7) Backup paths\n",
    "        base_dir = os.path.dirname(xlsx_file)\n",
    "        primary_backup_dir = os.path.join(base_dir, 'xlsx_backups', session_save_name, 'reach_curator_direct_backup')\n",
    "        primary_backup_file = os.path.join(primary_backup_dir, os.path.basename(xlsx_file))\n",
    "        added_backup_dir = os.path.join(base_dir, 'xlsx_backups', session_save_name, 'added_missing_rows_backup')\n",
    "        os.makedirs(added_backup_dir, exist_ok=True)\n",
    "        added_backup_file = os.path.join(added_backup_dir, os.path.basename(xlsx_file))\n",
    "\n",
    "        # 8) Save combined DataFrame and backups\n",
    "        if save_df:\n",
    "            if os.path.exists(primary_backup_file):\n",
    "                combined.to_excel(xlsx_file, index=False)\n",
    "                combined.to_excel(added_backup_file, index=False)\n",
    "                print(f\"✅ Final merged Excel saved to: {xlsx_file}\")\n",
    "                print(f\"✅ Added-rows backup saved to: {added_backup_file}\")\n",
    "                return combined, xlsx_file\n",
    "            else:\n",
    "                print(f\"⚠️ Warning: Primary backup missing at {primary_backup_file}\")\n",
    "                print(\"❌ Aborting: primary backup required before overwrite\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: save_df is False—DataFrame created but not saved to {xlsx_file}\")\n",
    "            return combined, None\n",
    "\n",
    "    def drop_empty_reach_rows(self):\n",
    "      \n",
    "        df = pd.read_excel(self.xlsx_file)\n",
    "        # back up the newly created xlsx file\n",
    "        backup_dir_02 = os.path.join(os.path.dirname(self.xlsx_file),'xlsx_backups', session_save_name,'completed_manual_curation_backup')\n",
    "        os.makedirs(backup_dir_02, exist_ok=True)\n",
    "        backup_file_path_02 = os.path.join(backup_dir_02, os.path.basename(self.xlsx_file))\n",
    "        if os.path.exists(backup_file_path_02):\n",
    "            print(f\"⚠️Warning: Backup file already exists at {backup_file_path_02}⚠️\")\n",
    "            print('❌ Stopping the script to avoid overwriting the backup file ❌')\n",
    "            return None \n",
    "        else:\n",
    "            # Copy the original file to the backup directory\n",
    "            shutil.copy2(self.xlsx_file, backup_file_path_02)\n",
    "            print(f\"✅ Backup saved to: {backup_file_path_02}\")\n",
    "        \"\"\"\n",
    "        Drop specified rows from the DataFrame.\n",
    "        \"\"\"\n",
    "        # Drop bad rows\n",
    "        df = df.dropna(subset=['reachInit']).reset_index(drop=True)\n",
    "         # save the DataFrame to the same xlsx file\n",
    "        if self.save_df:\n",
    "            df.to_excel(self.xlsx_file, index=False)\n",
    "            print(f\"✅ Final merged Excel saved to: {self.xlsx_file}\")   \n",
    "              \n",
    "        return df\n",
    "    \n",
    "    def load_orig_xlsx_file(self):\n",
    "        \"\"\"\n",
    "        Load the original xlsx file.\n",
    "        \"\"\"\n",
    "        original_dir = os.path.dirname(self.xlsx_file)\n",
    "        backup_dir = os.path.join(original_dir, 'xlsx_backups',session_save_name ,'reach_curator_direct_backup')\n",
    "        backup_file_path = os.path.join(backup_dir, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        df_orig = pd.read_excel(backup_file_path)\n",
    "        return df_orig, backup_file_path\n",
    "    \n",
    "    def load_added_rows_xlsx(self):\n",
    "        \"\"\"\n",
    "        Load the added rows xlsx file.\n",
    "        \"\"\"\n",
    "        original_dir = os.path.dirname(self.xlsx_file)-\n",
    "        backup_added_rows = os.path.join(original_dir,'xlsx_backups' ,session_save_name, 'added_missing_rows_backup')\n",
    "        backup_added_rows_file_path = os.path.join(backup_added_rows, os.path.basename(self.xlsx_file))\n",
    "\n",
    "        df_added_rows = pd.read_excel(backup_added_rows_file_path)\n",
    "        return df_added_rows, backup_added_rows_file_path\n",
    "    \n",
    "    \n",
    "    def load_final_xlsx(self):\n",
    "        \"\"\"\n",
    "        Load the combined xlsx file.\n",
    "        \"\"\"\n",
    "        df_final = pd.read_excel(self.xlsx_file)\n",
    "        return df_final, self.xlsx_file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_fail_modify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final merged Excel saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\20241204_christielab_session006.xlsx\n",
      "✅ Added-rows backup saved to: G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach7_20241204_session006\\added_missing_rows_backup\\20241204_christielab_session006.xlsx\n"
     ]
    }
   ],
   "source": [
    "if safe_fail_modify:\n",
    "    mouse_sessions = modify_curator_xlsx_file(xlsx_file, txt_file,save_df=True)\n",
    "    df_modied, xlsx_saved_file = mouse_sessions.create_new_xlxs_file()\n",
    "    df_orig, xlsx_orig_file = mouse_sessions.load_orig_xlsx_file()\n",
    "    df_added_rows, xlsx_added_rows_file = mouse_sessions.load_added_rows_xlsx()\n",
    "    df_final, xlsx_final_file = mouse_sessions.load_final_xlsx()\n",
    "    df_modied\n",
    "else:\n",
    "    print(f\"⚠️Warning: safe_fail actviated⚠️\")\n",
    "    print('if you want to run the code, please re-run this cell')\n",
    "    print('Note this ')\n",
    "    safe_fail_modify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>ReachType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2608</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>2827</td>\n",
       "      <td>dropped</td>\n",
       "      <td>2731.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4819</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>4973.0</td>\n",
       "      <td>4994.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4959</td>\n",
       "      <td>missed</td>\n",
       "      <td>4906.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4819</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>5021.0</td>\n",
       "      <td>5043.0</td>\n",
       "      <td>5047.0</td>\n",
       "      <td>4959</td>\n",
       "      <td>missed</td>\n",
       "      <td>4906.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7033</td>\n",
       "      <td>7121.0</td>\n",
       "      <td>7226.0</td>\n",
       "      <td>7257.0</td>\n",
       "      <td>7260.0</td>\n",
       "      <td>7252</td>\n",
       "      <td>missed</td>\n",
       "      <td>7119.0</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7033</td>\n",
       "      <td>7121.0</td>\n",
       "      <td>7264.0</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>7316.0</td>\n",
       "      <td>7252</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>7119.0</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T6000   T5000  reachInit  reachMax  reachEnd  stim       behaviors  \\\n",
       "0   2608  2733.0     2814.0    2832.0    2862.0  2827         dropped   \n",
       "1   4819  4908.0     4973.0    4994.0    5000.0  4959          missed   \n",
       "2   4819  4908.0     5021.0    5043.0    5047.0  4959          missed   \n",
       "3   7033  7121.0     7226.0    7257.0    7260.0  7252          missed   \n",
       "4   7033  7121.0     7264.0    7272.0    7316.0  7252  consumed_retry   \n",
       "\n",
       "   pellet_delivery  pellet_detected ReachType  \n",
       "0           2731.0           2806.0     right  \n",
       "1           4906.0           2806.0      long  \n",
       "2           4906.0           2806.0       NaN  \n",
       "3           7119.0           7194.0     short  \n",
       "4           7119.0           7194.0       NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing curated xlsx\n",
    "df_added_missing_rows = pd.read_excel(xlsx_saved_file)\n",
    "df_added_missing_rows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig, backup_file_path = mouse_sessions.load_orig_xlsx_file()\n",
    "df_added_missing_rows, backup_added_rows_file_path = mouse_sessions.load_added_rows_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading orginal_df for reach events from --> G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach7_20241204_session006\\reach_curator_direct_backup\\20241204_christielab_session006.xlsx\n",
      "loading df with missing rows added from--> G:\\Grant\\behavior_data\\DLC_net\\grant_reach7_swingDoor-christie\\Grant_curate\\xlsx_backups\\reach7_20241204_session006\\added_missing_rows_backup\\20241204_christielab_session006.xlsx\n",
      "\n",
      "Original reach events: 142\n",
      "Added reach events: 264\n",
      "\n",
      "❌ Reaches Missed: 122\n"
     ]
    }
   ],
   "source": [
    "orig_reach_count = df_orig.shape[0]\n",
    "added_row_count = df_added_missing_rows.shape[0]\n",
    "print(f'loading orginal_df for reach events from --> {backup_file_path}')\n",
    "print(f'loading df with missing rows added from--> {backup_added_rows_file_path}')\n",
    "# Count the number of reach events\n",
    "print('')\n",
    "print(f\"Original reach events total count: {len(df_orig)}\")\n",
    "print(f\"Added reach events total count: {len(df_added_missing_rows)}\")\n",
    "print('')\n",
    "print(f'❌ Reaches Missed: {added_row_count- orig_reach_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>Reach_type</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>ReachType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2814</td>\n",
       "      <td>2832</td>\n",
       "      <td>2862</td>\n",
       "      <td>2827</td>\n",
       "      <td>2731</td>\n",
       "      <td>2806</td>\n",
       "      <td>2608</td>\n",
       "      <td>2733</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4973</td>\n",
       "      <td>4994</td>\n",
       "      <td>5000</td>\n",
       "      <td>4959</td>\n",
       "      <td>4906</td>\n",
       "      <td>2806</td>\n",
       "      <td>4819</td>\n",
       "      <td>4908</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5021</td>\n",
       "      <td>5043</td>\n",
       "      <td>5047</td>\n",
       "      <td>4959</td>\n",
       "      <td>4906</td>\n",
       "      <td>2806</td>\n",
       "      <td>4819</td>\n",
       "      <td>4908</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7226</td>\n",
       "      <td>7257</td>\n",
       "      <td>7260</td>\n",
       "      <td>7252</td>\n",
       "      <td>7119</td>\n",
       "      <td>7194</td>\n",
       "      <td>7033</td>\n",
       "      <td>7121</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7264</td>\n",
       "      <td>7272</td>\n",
       "      <td>7316</td>\n",
       "      <td>7252</td>\n",
       "      <td>7119</td>\n",
       "      <td>7194</td>\n",
       "      <td>7033</td>\n",
       "      <td>7121</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9383</td>\n",
       "      <td>9409</td>\n",
       "      <td>9419</td>\n",
       "      <td>9424</td>\n",
       "      <td>9370</td>\n",
       "      <td>7194</td>\n",
       "      <td>9283</td>\n",
       "      <td>9373</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9426</td>\n",
       "      <td>9439</td>\n",
       "      <td>9500</td>\n",
       "      <td>9424</td>\n",
       "      <td>9370</td>\n",
       "      <td>7194</td>\n",
       "      <td>9283</td>\n",
       "      <td>9373</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24578</td>\n",
       "      <td>24599</td>\n",
       "      <td>24605</td>\n",
       "      <td>24589</td>\n",
       "      <td>24522</td>\n",
       "      <td>16119</td>\n",
       "      <td>24435</td>\n",
       "      <td>24524</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24645</td>\n",
       "      <td>24663</td>\n",
       "      <td>24671</td>\n",
       "      <td>24589</td>\n",
       "      <td>24522</td>\n",
       "      <td>16119</td>\n",
       "      <td>24435</td>\n",
       "      <td>24524</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39578</td>\n",
       "      <td>39603</td>\n",
       "      <td>39615</td>\n",
       "      <td>39590</td>\n",
       "      <td>39486</td>\n",
       "      <td>39561</td>\n",
       "      <td>39430</td>\n",
       "      <td>39488</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43856</td>\n",
       "      <td>43877</td>\n",
       "      <td>43882</td>\n",
       "      <td>43867</td>\n",
       "      <td>43765</td>\n",
       "      <td>43838</td>\n",
       "      <td>43677</td>\n",
       "      <td>43767</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43926</td>\n",
       "      <td>43952</td>\n",
       "      <td>44013</td>\n",
       "      <td>43867</td>\n",
       "      <td>43765</td>\n",
       "      <td>43838</td>\n",
       "      <td>43677</td>\n",
       "      <td>43767</td>\n",
       "      <td>0</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50460</td>\n",
       "      <td>50486</td>\n",
       "      <td>50528</td>\n",
       "      <td>50441</td>\n",
       "      <td>50291</td>\n",
       "      <td>50365</td>\n",
       "      <td>50204</td>\n",
       "      <td>50294</td>\n",
       "      <td>0</td>\n",
       "      <td>dropped</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>55034</td>\n",
       "      <td>55067</td>\n",
       "      <td>55077</td>\n",
       "      <td>55058</td>\n",
       "      <td>54866</td>\n",
       "      <td>54942</td>\n",
       "      <td>54780</td>\n",
       "      <td>54868</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55138</td>\n",
       "      <td>55176</td>\n",
       "      <td>55194</td>\n",
       "      <td>55058</td>\n",
       "      <td>54866</td>\n",
       "      <td>54942</td>\n",
       "      <td>54780</td>\n",
       "      <td>54868</td>\n",
       "      <td>0</td>\n",
       "      <td>missed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reachInit  reachMax  reachEnd   stim  pellet_delivery  pellet_detected  \\\n",
       "0        2814      2832      2862   2827             2731             2806   \n",
       "1        4973      4994      5000   4959             4906             2806   \n",
       "2        5021      5043      5047   4959             4906             2806   \n",
       "3        7226      7257      7260   7252             7119             7194   \n",
       "4        7264      7272      7316   7252             7119             7194   \n",
       "5        9383      9409      9419   9424             9370             7194   \n",
       "6        9426      9439      9500   9424             9370             7194   \n",
       "7       24578     24599     24605  24589            24522            16119   \n",
       "8       24645     24663     24671  24589            24522            16119   \n",
       "9       39578     39603     39615  39590            39486            39561   \n",
       "10      43856     43877     43882  43867            43765            43838   \n",
       "11      43926     43952     44013  43867            43765            43838   \n",
       "12      50460     50486     50528  50441            50291            50365   \n",
       "13      55034     55067     55077  55058            54866            54942   \n",
       "14      55138     55176     55194  55058            54866            54942   \n",
       "\n",
       "    T6000  T5000  Reach_type       behaviors ReachType  \n",
       "0    2608   2733           0         dropped     right  \n",
       "1    4819   4908           0          missed      long  \n",
       "2    4819   4908           0          missed       NaN  \n",
       "3    7033   7121           0          missed     short  \n",
       "4    7033   7121           0  consumed_retry       NaN  \n",
       "5    9283   9373           0          missed     right  \n",
       "6    9283   9373           0  consumed_retry       NaN  \n",
       "7   24435  24524           0          missed      long  \n",
       "8   24435  24524           0          missed       NaN  \n",
       "9   39430  39488           0          missed      long  \n",
       "10  43677  43767           0          missed     right  \n",
       "11  43677  43767           0  consumed_retry       NaN  \n",
       "12  50204  50294           0         dropped      long  \n",
       "13  54780  54868           0          missed     short  \n",
       "14  54780  54868           0          missed       NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T6000</th>\n",
       "      <th>T5000</th>\n",
       "      <th>reachInit</th>\n",
       "      <th>reachMax</th>\n",
       "      <th>reachEnd</th>\n",
       "      <th>stim</th>\n",
       "      <th>behaviors</th>\n",
       "      <th>pellet_delivery</th>\n",
       "      <th>pellet_detected</th>\n",
       "      <th>ReachType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2608</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>2827</td>\n",
       "      <td>dropped</td>\n",
       "      <td>2731.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4819</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>4973.0</td>\n",
       "      <td>4994.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4959</td>\n",
       "      <td>missed</td>\n",
       "      <td>4906.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4819</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>5021.0</td>\n",
       "      <td>5043.0</td>\n",
       "      <td>5047.0</td>\n",
       "      <td>4959</td>\n",
       "      <td>missed</td>\n",
       "      <td>4906.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7033</td>\n",
       "      <td>7121.0</td>\n",
       "      <td>7226.0</td>\n",
       "      <td>7257.0</td>\n",
       "      <td>7260.0</td>\n",
       "      <td>7252</td>\n",
       "      <td>missed</td>\n",
       "      <td>7119.0</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7033</td>\n",
       "      <td>7121.0</td>\n",
       "      <td>7264.0</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>7316.0</td>\n",
       "      <td>7252</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>7119.0</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9283</td>\n",
       "      <td>9373.0</td>\n",
       "      <td>9383.0</td>\n",
       "      <td>9409.0</td>\n",
       "      <td>9419.0</td>\n",
       "      <td>9424</td>\n",
       "      <td>missed</td>\n",
       "      <td>9370.0</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9283</td>\n",
       "      <td>9373.0</td>\n",
       "      <td>9426.0</td>\n",
       "      <td>9439.0</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>9424</td>\n",
       "      <td>consumed_retry</td>\n",
       "      <td>9370.0</td>\n",
       "      <td>7194.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11458</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11545.0</td>\n",
       "      <td>11619.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13819</td>\n",
       "      <td>13909.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13906.0</td>\n",
       "      <td>14019.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15956</td>\n",
       "      <td>16046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16044.0</td>\n",
       "      <td>16119.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20197</td>\n",
       "      <td>20287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24435</td>\n",
       "      <td>24524.0</td>\n",
       "      <td>24578.0</td>\n",
       "      <td>24599.0</td>\n",
       "      <td>24605.0</td>\n",
       "      <td>24589</td>\n",
       "      <td>missed</td>\n",
       "      <td>24522.0</td>\n",
       "      <td>16119.0</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24435</td>\n",
       "      <td>24524.0</td>\n",
       "      <td>24645.0</td>\n",
       "      <td>24663.0</td>\n",
       "      <td>24671.0</td>\n",
       "      <td>24589</td>\n",
       "      <td>missed</td>\n",
       "      <td>24522.0</td>\n",
       "      <td>16119.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26609</td>\n",
       "      <td>26735.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26733.0</td>\n",
       "      <td>26808.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30878</td>\n",
       "      <td>30937.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30934.0</td>\n",
       "      <td>31010.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    T6000    T5000  reachInit  reachMax  reachEnd   stim       behaviors  \\\n",
       "0    2608   2733.0     2814.0    2832.0    2862.0   2827         dropped   \n",
       "1    4819   4908.0     4973.0    4994.0    5000.0   4959          missed   \n",
       "2    4819   4908.0     5021.0    5043.0    5047.0   4959          missed   \n",
       "3    7033   7121.0     7226.0    7257.0    7260.0   7252          missed   \n",
       "4    7033   7121.0     7264.0    7272.0    7316.0   7252  consumed_retry   \n",
       "5    9283   9373.0     9383.0    9409.0    9419.0   9424          missed   \n",
       "6    9283   9373.0     9426.0    9439.0    9500.0   9424  consumed_retry   \n",
       "7   11458  11547.0        NaN       NaN       NaN      0             NaN   \n",
       "8   13819  13909.0        NaN       NaN       NaN      0             NaN   \n",
       "9   15956  16046.0        NaN       NaN       NaN      0             NaN   \n",
       "10  20197  20287.0        NaN       NaN       NaN      0             NaN   \n",
       "11  24435  24524.0    24578.0   24599.0   24605.0  24589          missed   \n",
       "12  24435  24524.0    24645.0   24663.0   24671.0  24589          missed   \n",
       "13  26609  26735.0        NaN       NaN       NaN      0             NaN   \n",
       "14  30878  30937.0        NaN       NaN       NaN      0             NaN   \n",
       "\n",
       "    pellet_delivery  pellet_detected ReachType  \n",
       "0            2731.0           2806.0     right  \n",
       "1            4906.0           2806.0      long  \n",
       "2            4906.0           2806.0       NaN  \n",
       "3            7119.0           7194.0     short  \n",
       "4            7119.0           7194.0       NaN  \n",
       "5            9370.0           7194.0     right  \n",
       "6            9370.0           7194.0       NaN  \n",
       "7           11545.0          11619.0       NaN  \n",
       "8           13906.0          14019.0       NaN  \n",
       "9           16044.0          16119.0       NaN  \n",
       "10          20285.0              NaN       NaN  \n",
       "11          24522.0          16119.0      long  \n",
       "12          24522.0          16119.0       NaN  \n",
       "13          26733.0          26808.0       NaN  \n",
       "14          30934.0          31010.0       NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_added_missing_rows.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❌ END ❌\n",
    "\n",
    "\n",
    "### ✅ Next Steps\n",
    "1. Go back to reach_Curator_p38_v3.py, and simply launch it liuke normal. then manually place all the reaches you need \n",
    "\n",
    "2. Once 100% done adding reachs and label. open the analyze_curated_reach_results.ipynb file (its in the same folder as this notebook)\n",
    "    - then simply run that file\n",
    "    - it will first back up your manaual curation .xlsx file too --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/completed_manual_curation_backup\n",
    "    - it will extract / drop all empty rows from that .xlsx file and save the final version too -->  Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/final_backup\n",
    "    - and it will save this final_df to the root folder, so the reach_curator can load it in --> Grant_curate/final_xlsx_file.xlsx \n",
    "\n",
    "\n",
    "# ✅ Results of file\n",
    "1. you have created a duplicate of the .xlsx file that the reach_curator_py38_v3.py makes when you load in a session for the first time \n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/reach_curator_direct_backup\n",
    "    - Note, this file is missing all the T6000 and T5000 rows that the find_reach_events.ipynb did not associate a reach too\n",
    "2. you have created a new .xlsx file that now containes every sinlge row, meaning it added rows for every single T6000 > T5000, and left the reachInit > reachMax > reachEnd vlaues empty, this way you can manually go into the curator and add reaches for these rows\n",
    "    - Backup location --> Grant_curate/xlsx_backups/mouse_sessionDate_sessionID/added_missing_rows_backup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reaching_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
